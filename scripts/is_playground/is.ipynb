{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import espaloma as esp\n",
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simtk import unit\n",
    "GAS_CONSTANT = 8.31446261815324 * unit.joule / (unit.kelvin * unit.mole)\n",
    "GAS_CONSTANT = GAS_CONSTANT.value_in_unit(\n",
    "    esp.units.ENERGY_UNIT / (unit.kelvin)\n",
    ")\n",
    "kT = GAS_CONSTANT * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOWS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leapfrog(xs, vs, closure, dt=1.0):\n",
    "    x = xs[-1]\n",
    "    v = vs[-1]\n",
    "\n",
    "    x = x + v * dt\n",
    "\n",
    "    energy_old = closure(x)\n",
    "\n",
    "    a = -torch.autograd.grad(\n",
    "        energy_old.sum(),\n",
    "        [x],\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    v = v + a * dt\n",
    "\n",
    "    x = x + v * dt\n",
    "\n",
    "    vs.append(v)\n",
    "    xs.append(x)\n",
    "\n",
    "    return xs, vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = esp.Graph('CC')\n",
    "g = esp.graphs.LegacyForceField('smirnoff99Frosst').parametrize(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = esp.nn.dgl_legacy.gn()\n",
    "\n",
    "representation = esp.nn.Sequential(\n",
    "    layer,\n",
    "    [32, 'leaky_relu', 128, 'leaky_relu', 128, 'leaky_relu'],\n",
    ")\n",
    "\n",
    "readout = esp.nn.readout.janossy.JanossyPooling(\n",
    "    in_features=128,\n",
    "    config=[128, 'leaky_relu', 128, 'leaky_relu'],\n",
    "    out_features={\n",
    "        1: {'epsilons': WINDOWS, 'sigma': 1, 'log_alpha': WINDOWS},\n",
    "        2: {'ks': WINDOWS, 'eqs': WINDOWS},\n",
    "        3: {'ks': WINDOWS, 'eqs': WINDOWS},\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "net = torch.nn.Sequential(\n",
    "    representation,\n",
    "    readout,\n",
    ")\n",
    "\n",
    "realize = torch.nn.Sequential(\n",
    "    esp.mm.geometry.GeometryInGraph(),\n",
    "    esp.mm.energy.EnergyInGraph(suffix='_ref', terms=['n2', 'n3']),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure(x, idx, g=g):\n",
    "    with g.heterograph.local_scope():\n",
    "        g.nodes['n1'].data['xyz'] = x\n",
    "        \n",
    "        \n",
    "        if idx != -1:\n",
    "\n",
    "            g.nodes['n2'].data['eq_ref'] = g.nodes['n2'].data['eqs'][:, idx][:, None].exp()\n",
    "            g.nodes['n2'].data['k_ref'] = g.nodes['n2'].data['ks'][:, idx][:, None].exp()\n",
    "\n",
    "            g.nodes['n3'].data['eq_ref'] = g.nodes['n3'].data['eqs'][:, idx][:, None].exp()\n",
    "            g.nodes['n3'].data['k_ref'] = g.nodes['n3'].data['ks'][:, idx][:, None].exp()\n",
    "            \n",
    "        realize(g.heterograph)\n",
    "        return g.nodes['g'].data['u_ref']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(net, g=g):\n",
    "    with g.heterograph.local_scope():\n",
    "        net(g.heterograph)\n",
    "        \n",
    "        log_alpha = g.nodes['n1'].data['log_alpha']\n",
    "        \n",
    "        det_j = log_alpha.sum(dim=-1)\n",
    "        \n",
    "        x0_distribution = torch.distributions.normal.Normal(\n",
    "            loc=torch.zeros(g.heterograph.number_of_nodes('n1'), 128, 3),\n",
    "            scale=g.nodes['n1'].data['sigma'][:, :, None].repeat(1, 128, 3).exp()\n",
    "        )\n",
    "        \n",
    "        normal_distribution = torch.distributions.normal.Normal(0, 1.0)\n",
    "        \n",
    "        x = torch.nn.Parameter(\n",
    "            x0_distribution.rsample()\n",
    "        )\n",
    "        \n",
    "        v = torch.nn.Parameter(\n",
    "            normal_distribution.rsample(\n",
    "                sample_shape=(g.heterograph.number_of_nodes('n1'), 128, 3),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        xs = [x]\n",
    "        vs = [v]\n",
    "\n",
    "        for idx in range(1, WINDOWS):\n",
    "            \n",
    "            alpha = g.heterograph.nodes['n1'].data['log_alpha'][:, idx].exp()\n",
    "            \n",
    "            \n",
    "            vs[-1] = vs[-1] * alpha[:, None, None].repeat(1, 128, 3)\n",
    "\n",
    "            xs, vs = leapfrog(xs, vs, lambda x: closure(x, idx, g=g), 1e-2)\n",
    "            \n",
    "        return xs, vs, x0_distribution, det_j\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(692047.0625, grad_fn=<AddBackward0>) tensor(220.4890, grad_fn=<SumBackward0>)\n",
      "tensor(678104.8125, grad_fn=<AddBackward0>) tensor(216.0744, grad_fn=<SumBackward0>)\n",
      "tensor(676757.7500, grad_fn=<AddBackward0>) tensor(215.6292, grad_fn=<SumBackward0>)\n",
      "tensor(698891.3750, grad_fn=<AddBackward0>) tensor(222.6654, grad_fn=<SumBackward0>)\n",
      "tensor(711689.4375, grad_fn=<AddBackward0>) tensor(226.7283, grad_fn=<SumBackward0>)\n",
      "tensor(682037.3750, grad_fn=<AddBackward0>) tensor(217.3112, grad_fn=<SumBackward0>)\n",
      "tensor(679493.4375, grad_fn=<AddBackward0>) tensor(216.5321, grad_fn=<SumBackward0>)\n",
      "tensor(705563.6875, grad_fn=<AddBackward0>) tensor(224.7747, grad_fn=<SumBackward0>)\n",
      "tensor(675196.6250, grad_fn=<AddBackward0>) tensor(215.1838, grad_fn=<SumBackward0>)\n",
      "tensor(683526.1875, grad_fn=<AddBackward0>) tensor(217.7725, grad_fn=<SumBackward0>)\n",
      "tensor(712141.8125, grad_fn=<AddBackward0>) tensor(226.8586, grad_fn=<SumBackward0>)\n",
      "tensor(696719.8750, grad_fn=<AddBackward0>) tensor(221.9681, grad_fn=<SumBackward0>)\n",
      "tensor(719641.1875, grad_fn=<AddBackward0>) tensor(229.2466, grad_fn=<SumBackward0>)\n",
      "tensor(695038., grad_fn=<AddBackward0>) tensor(221.4376, grad_fn=<SumBackward0>)\n",
      "tensor(665570.7500, grad_fn=<AddBackward0>) tensor(212.0943, grad_fn=<SumBackward0>)\n",
      "tensor(682461.1250, grad_fn=<AddBackward0>) tensor(217.4818, grad_fn=<SumBackward0>)\n",
      "tensor(694478., grad_fn=<AddBackward0>) tensor(221.2861, grad_fn=<SumBackward0>)\n",
      "tensor(678921.7500, grad_fn=<AddBackward0>) tensor(216.3565, grad_fn=<SumBackward0>)\n",
      "tensor(643307.5000, grad_fn=<AddBackward0>) tensor(205.0582, grad_fn=<SumBackward0>)\n",
      "tensor(723890.1875, grad_fn=<AddBackward0>) tensor(230.5986, grad_fn=<SumBackward0>)\n",
      "tensor(650859.8125, grad_fn=<AddBackward0>) tensor(207.4510, grad_fn=<SumBackward0>)\n",
      "tensor(684009.7500, grad_fn=<AddBackward0>) tensor(217.9530, grad_fn=<SumBackward0>)\n",
      "tensor(691195.6875, grad_fn=<AddBackward0>) tensor(220.2267, grad_fn=<SumBackward0>)\n",
      "tensor(685340.3125, grad_fn=<AddBackward0>) tensor(218.3724, grad_fn=<SumBackward0>)\n",
      "tensor(718212.8125, grad_fn=<AddBackward0>) tensor(228.7904, grad_fn=<SumBackward0>)\n",
      "tensor(665075.7500, grad_fn=<AddBackward0>) tensor(211.9528, grad_fn=<SumBackward0>)\n",
      "tensor(705405.8125, grad_fn=<AddBackward0>) tensor(224.7117, grad_fn=<SumBackward0>)\n",
      "tensor(692087.0625, grad_fn=<AddBackward0>) tensor(220.5131, grad_fn=<SumBackward0>)\n",
      "tensor(693425.5625, grad_fn=<AddBackward0>) tensor(220.9365, grad_fn=<SumBackward0>)\n",
      "tensor(697904.8125, grad_fn=<AddBackward0>) tensor(222.3625, grad_fn=<SumBackward0>)\n",
      "tensor(681013.8750, grad_fn=<AddBackward0>) tensor(217.0320, grad_fn=<SumBackward0>)\n",
      "tensor(701979.2500, grad_fn=<AddBackward0>) tensor(223.6642, grad_fn=<SumBackward0>)\n",
      "tensor(704074.1875, grad_fn=<AddBackward0>) tensor(224.3383, grad_fn=<SumBackward0>)\n",
      "tensor(673735.6250, grad_fn=<AddBackward0>) tensor(214.6937, grad_fn=<SumBackward0>)\n",
      "tensor(672485.1875, grad_fn=<AddBackward0>) tensor(214.3052, grad_fn=<SumBackward0>)\n",
      "tensor(717647.5000, grad_fn=<AddBackward0>) tensor(228.6076, grad_fn=<SumBackward0>)\n",
      "tensor(673343.3125, grad_fn=<AddBackward0>) tensor(214.5821, grad_fn=<SumBackward0>)\n",
      "tensor(679101.8750, grad_fn=<AddBackward0>) tensor(216.4055, grad_fn=<SumBackward0>)\n",
      "tensor(728654.8125, grad_fn=<AddBackward0>) tensor(232.1048, grad_fn=<SumBackward0>)\n",
      "tensor(673102.2500, grad_fn=<AddBackward0>) tensor(214.4989, grad_fn=<SumBackward0>)\n",
      "tensor(719507.8125, grad_fn=<AddBackward0>) tensor(229.2244, grad_fn=<SumBackward0>)\n",
      "tensor(665750.8125, grad_fn=<AddBackward0>) tensor(212.1847, grad_fn=<SumBackward0>)\n",
      "tensor(686077.6875, grad_fn=<AddBackward0>) tensor(218.6012, grad_fn=<SumBackward0>)\n",
      "tensor(665067.4375, grad_fn=<AddBackward0>) tensor(211.9479, grad_fn=<SumBackward0>)\n",
      "tensor(704335.5625, grad_fn=<AddBackward0>) tensor(224.4243, grad_fn=<SumBackward0>)\n",
      "tensor(697323.7500, grad_fn=<AddBackward0>) tensor(222.2114, grad_fn=<SumBackward0>)\n",
      "tensor(691770.1250, grad_fn=<AddBackward0>) tensor(220.4211, grad_fn=<SumBackward0>)\n",
      "tensor(691241.4375, grad_fn=<AddBackward0>) tensor(220.2609, grad_fn=<SumBackward0>)\n",
      "tensor(723600.3750, grad_fn=<AddBackward0>) tensor(230.5196, grad_fn=<SumBackward0>)\n",
      "tensor(715158.5625, grad_fn=<AddBackward0>) tensor(227.8510, grad_fn=<SumBackward0>)\n",
      "tensor(684795.5000, grad_fn=<AddBackward0>) tensor(218.2172, grad_fn=<SumBackward0>)\n",
      "tensor(682420.3750, grad_fn=<AddBackward0>) tensor(217.4655, grad_fn=<SumBackward0>)\n",
      "tensor(653387., grad_fn=<AddBackward0>) tensor(208.2638, grad_fn=<SumBackward0>)\n",
      "tensor(651550.7500, grad_fn=<AddBackward0>) tensor(207.6868, grad_fn=<SumBackward0>)\n",
      "tensor(700270.1875, grad_fn=<AddBackward0>) tensor(223.1381, grad_fn=<SumBackward0>)\n",
      "tensor(686406.6250, grad_fn=<AddBackward0>) tensor(218.7280, grad_fn=<SumBackward0>)\n",
      "tensor(703089.9375, grad_fn=<AddBackward0>) tensor(224.0086, grad_fn=<SumBackward0>)\n",
      "tensor(698680.7500, grad_fn=<AddBackward0>) tensor(222.6065, grad_fn=<SumBackward0>)\n",
      "tensor(686795.8125, grad_fn=<AddBackward0>) tensor(218.8790, grad_fn=<SumBackward0>)\n",
      "tensor(718731.4375, grad_fn=<AddBackward0>) tensor(228.9921, grad_fn=<SumBackward0>)\n",
      "tensor(671680.6250, grad_fn=<AddBackward0>) tensor(214.1007, grad_fn=<SumBackward0>)\n",
      "tensor(683760.1250, grad_fn=<AddBackward0>) tensor(217.8833, grad_fn=<SumBackward0>)\n",
      "tensor(708979., grad_fn=<AddBackward0>) tensor(225.8912, grad_fn=<SumBackward0>)\n",
      "tensor(720736., grad_fn=<AddBackward0>) tensor(229.6225, grad_fn=<SumBackward0>)\n",
      "tensor(646062.1875, grad_fn=<AddBackward0>) tensor(205.9560, grad_fn=<SumBackward0>)\n",
      "tensor(688173.4375, grad_fn=<AddBackward0>) tensor(219.2944, grad_fn=<SumBackward0>)\n",
      "tensor(662754.4375, grad_fn=<AddBackward0>) tensor(211.2360, grad_fn=<SumBackward0>)\n",
      "tensor(684713.5625, grad_fn=<AddBackward0>) tensor(218.1952, grad_fn=<SumBackward0>)\n",
      "tensor(699998.8750, grad_fn=<AddBackward0>) tensor(223.0378, grad_fn=<SumBackward0>)\n",
      "tensor(694949.4375, grad_fn=<AddBackward0>) tensor(221.4454, grad_fn=<SumBackward0>)\n",
      "tensor(681101.5000, grad_fn=<AddBackward0>) tensor(217.0747, grad_fn=<SumBackward0>)\n",
      "tensor(695297.1250, grad_fn=<AddBackward0>) tensor(221.5537, grad_fn=<SumBackward0>)\n",
      "tensor(666816.6875, grad_fn=<AddBackward0>) tensor(212.5404, grad_fn=<SumBackward0>)\n",
      "tensor(701454.0625, grad_fn=<AddBackward0>) tensor(223.4948, grad_fn=<SumBackward0>)\n",
      "tensor(681510.9375, grad_fn=<AddBackward0>) tensor(217.1942, grad_fn=<SumBackward0>)\n",
      "tensor(682987., grad_fn=<AddBackward0>) tensor(217.6511, grad_fn=<SumBackward0>)\n",
      "tensor(693948.6875, grad_fn=<AddBackward0>) tensor(221.1426, grad_fn=<SumBackward0>)\n",
      "tensor(673357.3750, grad_fn=<AddBackward0>) tensor(214.6241, grad_fn=<SumBackward0>)\n",
      "tensor(699691.3125, grad_fn=<AddBackward0>) tensor(222.9429, grad_fn=<SumBackward0>)\n",
      "tensor(699908.1250, grad_fn=<AddBackward0>) tensor(223.0228, grad_fn=<SumBackward0>)\n",
      "tensor(681434.9375, grad_fn=<AddBackward0>) tensor(217.1468, grad_fn=<SumBackward0>)\n",
      "tensor(692903.2500, grad_fn=<AddBackward0>) tensor(220.8050, grad_fn=<SumBackward0>)\n",
      "tensor(698390.0625, grad_fn=<AddBackward0>) tensor(222.5733, grad_fn=<SumBackward0>)\n",
      "tensor(718176.3750, grad_fn=<AddBackward0>) tensor(228.8114, grad_fn=<SumBackward0>)\n",
      "tensor(657479.8125, grad_fn=<AddBackward0>) tensor(209.6096, grad_fn=<SumBackward0>)\n",
      "tensor(702561.7500, grad_fn=<AddBackward0>) tensor(223.8506, grad_fn=<SumBackward0>)\n",
      "tensor(691319.2500, grad_fn=<AddBackward0>) tensor(220.3177, grad_fn=<SumBackward0>)\n",
      "tensor(695275.3125, grad_fn=<AddBackward0>) tensor(221.5529, grad_fn=<SumBackward0>)\n",
      "tensor(702614.5000, grad_fn=<AddBackward0>) tensor(223.8894, grad_fn=<SumBackward0>)\n",
      "tensor(682273.9375, grad_fn=<AddBackward0>) tensor(217.4499, grad_fn=<SumBackward0>)\n",
      "tensor(664806.6875, grad_fn=<AddBackward0>) tensor(211.8961, grad_fn=<SumBackward0>)\n",
      "tensor(654983.4375, grad_fn=<AddBackward0>) tensor(208.8113, grad_fn=<SumBackward0>)\n",
      "tensor(686909.3125, grad_fn=<AddBackward0>) tensor(218.8859, grad_fn=<SumBackward0>)\n",
      "tensor(681340.5625, grad_fn=<AddBackward0>) tensor(217.1456, grad_fn=<SumBackward0>)\n",
      "tensor(676844.3750, grad_fn=<AddBackward0>) tensor(215.7168, grad_fn=<SumBackward0>)\n",
      "tensor(680728.5000, grad_fn=<AddBackward0>) tensor(216.9478, grad_fn=<SumBackward0>)\n",
      "tensor(702587., grad_fn=<AddBackward0>) tensor(223.8835, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(710943.1250, grad_fn=<AddBackward0>) tensor(226.5313, grad_fn=<SumBackward0>)\n",
      "tensor(677759.3750, grad_fn=<AddBackward0>) tensor(216.0126, grad_fn=<SumBackward0>)\n",
      "tensor(696880.0625, grad_fn=<AddBackward0>) tensor(222.0813, grad_fn=<SumBackward0>)\n",
      "tensor(678589., grad_fn=<AddBackward0>) tensor(216.2636, grad_fn=<SumBackward0>)\n",
      "tensor(703897.7500, grad_fn=<AddBackward0>) tensor(224.2740, grad_fn=<SumBackward0>)\n",
      "tensor(699991.5000, grad_fn=<AddBackward0>) tensor(223.0583, grad_fn=<SumBackward0>)\n",
      "tensor(669615.6250, grad_fn=<AddBackward0>) tensor(213.4151, grad_fn=<SumBackward0>)\n",
      "tensor(689949., grad_fn=<AddBackward0>) tensor(219.8888, grad_fn=<SumBackward0>)\n",
      "tensor(663527., grad_fn=<AddBackward0>) tensor(211.5061, grad_fn=<SumBackward0>)\n",
      "tensor(714100.6875, grad_fn=<AddBackward0>) tensor(227.5244, grad_fn=<SumBackward0>)\n",
      "tensor(664065.7500, grad_fn=<AddBackward0>) tensor(211.6542, grad_fn=<SumBackward0>)\n",
      "tensor(694262.9375, grad_fn=<AddBackward0>) tensor(221.2455, grad_fn=<SumBackward0>)\n",
      "tensor(705560.5625, grad_fn=<AddBackward0>) tensor(224.8069, grad_fn=<SumBackward0>)\n",
      "tensor(643164.8125, grad_fn=<AddBackward0>) tensor(205.0583, grad_fn=<SumBackward0>)\n",
      "tensor(678948.3125, grad_fn=<AddBackward0>) tensor(216.3852, grad_fn=<SumBackward0>)\n",
      "tensor(656326.3125, grad_fn=<AddBackward0>) tensor(209.2231, grad_fn=<SumBackward0>)\n",
      "tensor(649003.6250, grad_fn=<AddBackward0>) tensor(206.8945, grad_fn=<SumBackward0>)\n",
      "tensor(685040., grad_fn=<AddBackward0>) tensor(218.3264, grad_fn=<SumBackward0>)\n",
      "tensor(663020.1250, grad_fn=<AddBackward0>) tensor(211.3412, grad_fn=<SumBackward0>)\n",
      "tensor(685479.3125, grad_fn=<AddBackward0>) tensor(218.4552, grad_fn=<SumBackward0>)\n",
      "tensor(691272.1250, grad_fn=<AddBackward0>) tensor(220.2904, grad_fn=<SumBackward0>)\n",
      "tensor(664647.3125, grad_fn=<AddBackward0>) tensor(211.8566, grad_fn=<SumBackward0>)\n",
      "tensor(683455.3125, grad_fn=<AddBackward0>) tensor(217.8262, grad_fn=<SumBackward0>)\n",
      "tensor(676956.2500, grad_fn=<AddBackward0>) tensor(215.7625, grad_fn=<SumBackward0>)\n",
      "tensor(707383., grad_fn=<AddBackward0>) tensor(225.3904, grad_fn=<SumBackward0>)\n",
      "tensor(651434.3750, grad_fn=<AddBackward0>) tensor(207.6567, grad_fn=<SumBackward0>)\n",
      "tensor(693053.3125, grad_fn=<AddBackward0>) tensor(220.8272, grad_fn=<SumBackward0>)\n",
      "tensor(699335.0625, grad_fn=<AddBackward0>) tensor(222.8660, grad_fn=<SumBackward0>)\n",
      "tensor(705750.5625, grad_fn=<AddBackward0>) tensor(224.8849, grad_fn=<SumBackward0>)\n",
      "tensor(673430.7500, grad_fn=<AddBackward0>) tensor(214.6268, grad_fn=<SumBackward0>)\n",
      "tensor(692538.7500, grad_fn=<AddBackward0>) tensor(220.7110, grad_fn=<SumBackward0>)\n",
      "tensor(647257., grad_fn=<AddBackward0>) tensor(206.3293, grad_fn=<SumBackward0>)\n",
      "tensor(704398.3125, grad_fn=<AddBackward0>) tensor(224.4468, grad_fn=<SumBackward0>)\n",
      "tensor(669088.3750, grad_fn=<AddBackward0>) tensor(213.2529, grad_fn=<SumBackward0>)\n",
      "tensor(696440.8750, grad_fn=<AddBackward0>) tensor(221.9391, grad_fn=<SumBackward0>)\n",
      "tensor(653575., grad_fn=<AddBackward0>) tensor(208.3499, grad_fn=<SumBackward0>)\n",
      "tensor(670558.7500, grad_fn=<AddBackward0>) tensor(213.7220, grad_fn=<SumBackward0>)\n",
      "tensor(647727.2500, grad_fn=<AddBackward0>) tensor(206.4888, grad_fn=<SumBackward0>)\n",
      "tensor(657701.9375, grad_fn=<AddBackward0>) tensor(209.6617, grad_fn=<SumBackward0>)\n",
      "tensor(712643., grad_fn=<AddBackward0>) tensor(227.0645, grad_fn=<SumBackward0>)\n",
      "tensor(666548.7500, grad_fn=<AddBackward0>) tensor(212.4725, grad_fn=<SumBackward0>)\n",
      "tensor(688195.8750, grad_fn=<AddBackward0>) tensor(219.3459, grad_fn=<SumBackward0>)\n",
      "tensor(696354.4375, grad_fn=<AddBackward0>) tensor(221.9161, grad_fn=<SumBackward0>)\n",
      "tensor(695730.0625, grad_fn=<AddBackward0>) tensor(221.6924, grad_fn=<SumBackward0>)\n",
      "tensor(694581.4375, grad_fn=<AddBackward0>) tensor(221.3596, grad_fn=<SumBackward0>)\n",
      "tensor(684271.5000, grad_fn=<AddBackward0>) tensor(218.0806, grad_fn=<SumBackward0>)\n",
      "tensor(693139.6875, grad_fn=<AddBackward0>) tensor(220.8829, grad_fn=<SumBackward0>)\n",
      "tensor(671436.9375, grad_fn=<AddBackward0>) tensor(214.0068, grad_fn=<SumBackward0>)\n",
      "tensor(734764.3750, grad_fn=<AddBackward0>) tensor(234.0964, grad_fn=<SumBackward0>)\n",
      "tensor(677446.8750, grad_fn=<AddBackward0>) tensor(215.9048, grad_fn=<SumBackward0>)\n",
      "tensor(665558.3750, grad_fn=<AddBackward0>) tensor(212.1376, grad_fn=<SumBackward0>)\n",
      "tensor(665361.3125, grad_fn=<AddBackward0>) tensor(212.0911, grad_fn=<SumBackward0>)\n",
      "tensor(641961.3750, grad_fn=<AddBackward0>) tensor(204.6788, grad_fn=<SumBackward0>)\n",
      "tensor(660930.6250, grad_fn=<AddBackward0>) tensor(210.6785, grad_fn=<SumBackward0>)\n",
      "tensor(684350., grad_fn=<AddBackward0>) tensor(218.0995, grad_fn=<SumBackward0>)\n",
      "tensor(659687.0625, grad_fn=<AddBackward0>) tensor(210.2912, grad_fn=<SumBackward0>)\n",
      "tensor(636429., grad_fn=<AddBackward0>) tensor(202.9112, grad_fn=<SumBackward0>)\n",
      "tensor(667992.3125, grad_fn=<AddBackward0>) tensor(212.9037, grad_fn=<SumBackward0>)\n",
      "tensor(703761.6875, grad_fn=<AddBackward0>) tensor(224.2844, grad_fn=<SumBackward0>)\n",
      "tensor(674956.6875, grad_fn=<AddBackward0>) tensor(215.1336, grad_fn=<SumBackward0>)\n",
      "tensor(679583., grad_fn=<AddBackward0>) tensor(216.6004, grad_fn=<SumBackward0>)\n",
      "tensor(714934.5625, grad_fn=<AddBackward0>) tensor(227.7915, grad_fn=<SumBackward0>)\n",
      "tensor(672539.6250, grad_fn=<AddBackward0>) tensor(214.3765, grad_fn=<SumBackward0>)\n",
      "tensor(671372.7500, grad_fn=<AddBackward0>) tensor(214.0003, grad_fn=<SumBackward0>)\n",
      "tensor(707291.2500, grad_fn=<AddBackward0>) tensor(225.3919, grad_fn=<SumBackward0>)\n",
      "tensor(709008.5000, grad_fn=<AddBackward0>) tensor(225.8968, grad_fn=<SumBackward0>)\n",
      "tensor(688550.3125, grad_fn=<AddBackward0>) tensor(219.4242, grad_fn=<SumBackward0>)\n",
      "tensor(673240.6250, grad_fn=<AddBackward0>) tensor(214.5722, grad_fn=<SumBackward0>)\n",
      "tensor(667786.7500, grad_fn=<AddBackward0>) tensor(212.8747, grad_fn=<SumBackward0>)\n",
      "tensor(696694.4375, grad_fn=<AddBackward0>) tensor(221.9893, grad_fn=<SumBackward0>)\n",
      "tensor(656033.1250, grad_fn=<AddBackward0>) tensor(209.1298, grad_fn=<SumBackward0>)\n",
      "tensor(688142.1875, grad_fn=<AddBackward0>) tensor(219.2788, grad_fn=<SumBackward0>)\n",
      "tensor(656906.0625, grad_fn=<AddBackward0>) tensor(209.4194, grad_fn=<SumBackward0>)\n",
      "tensor(658303., grad_fn=<AddBackward0>) tensor(209.8552, grad_fn=<SumBackward0>)\n",
      "tensor(667620.5625, grad_fn=<AddBackward0>) tensor(212.7956, grad_fn=<SumBackward0>)\n",
      "tensor(680917.2500, grad_fn=<AddBackward0>) tensor(217.0133, grad_fn=<SumBackward0>)\n",
      "tensor(680724.4375, grad_fn=<AddBackward0>) tensor(216.9657, grad_fn=<SumBackward0>)\n",
      "tensor(683218.9375, grad_fn=<AddBackward0>) tensor(217.7565, grad_fn=<SumBackward0>)\n",
      "tensor(669480., grad_fn=<AddBackward0>) tensor(213.3960, grad_fn=<SumBackward0>)\n",
      "tensor(670414.8125, grad_fn=<AddBackward0>) tensor(213.6708, grad_fn=<SumBackward0>)\n",
      "tensor(661689.5000, grad_fn=<AddBackward0>) tensor(210.9209, grad_fn=<SumBackward0>)\n",
      "tensor(714819.0625, grad_fn=<AddBackward0>) tensor(227.7521, grad_fn=<SumBackward0>)\n",
      "tensor(647052.0625, grad_fn=<AddBackward0>) tensor(206.2851, grad_fn=<SumBackward0>)\n",
      "tensor(680809.1250, grad_fn=<AddBackward0>) tensor(217.0019, grad_fn=<SumBackward0>)\n",
      "tensor(666384.0625, grad_fn=<AddBackward0>) tensor(212.3988, grad_fn=<SumBackward0>)\n",
      "tensor(676597.5625, grad_fn=<AddBackward0>) tensor(215.6370, grad_fn=<SumBackward0>)\n",
      "tensor(670591.8125, grad_fn=<AddBackward0>) tensor(213.7392, grad_fn=<SumBackward0>)\n",
      "tensor(683288.3125, grad_fn=<AddBackward0>) tensor(217.7785, grad_fn=<SumBackward0>)\n",
      "tensor(686615.0625, grad_fn=<AddBackward0>) tensor(218.8366, grad_fn=<SumBackward0>)\n",
      "tensor(685036.1250, grad_fn=<AddBackward0>) tensor(218.3230, grad_fn=<SumBackward0>)\n",
      "tensor(695327.6250, grad_fn=<AddBackward0>) tensor(221.5901, grad_fn=<SumBackward0>)\n",
      "tensor(684786.4375, grad_fn=<AddBackward0>) tensor(218.2563, grad_fn=<SumBackward0>)\n",
      "tensor(688559.3750, grad_fn=<AddBackward0>) tensor(219.4260, grad_fn=<SumBackward0>)\n",
      "tensor(711722.8125, grad_fn=<AddBackward0>) tensor(226.7851, grad_fn=<SumBackward0>)\n",
      "tensor(673437.1875, grad_fn=<AddBackward0>) tensor(214.6155, grad_fn=<SumBackward0>)\n",
      "tensor(720199.6250, grad_fn=<AddBackward0>) tensor(229.4490, grad_fn=<SumBackward0>)\n",
      "tensor(690498.2500, grad_fn=<AddBackward0>) tensor(220.0441, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(672200.9375, grad_fn=<AddBackward0>) tensor(214.2614, grad_fn=<SumBackward0>)\n",
      "tensor(684730.7500, grad_fn=<AddBackward0>) tensor(218.2350, grad_fn=<SumBackward0>)\n",
      "tensor(637429.3750, grad_fn=<AddBackward0>) tensor(203.2231, grad_fn=<SumBackward0>)\n",
      "tensor(697445.9375, grad_fn=<AddBackward0>) tensor(222.2672, grad_fn=<SumBackward0>)\n",
      "tensor(668829.8125, grad_fn=<AddBackward0>) tensor(213.1721, grad_fn=<SumBackward0>)\n",
      "tensor(681700.4375, grad_fn=<AddBackward0>) tensor(217.2567, grad_fn=<SumBackward0>)\n",
      "tensor(665894.5000, grad_fn=<AddBackward0>) tensor(212.2390, grad_fn=<SumBackward0>)\n",
      "tensor(664668.0625, grad_fn=<AddBackward0>) tensor(211.8493, grad_fn=<SumBackward0>)\n",
      "tensor(692245.5625, grad_fn=<AddBackward0>) tensor(220.6028, grad_fn=<SumBackward0>)\n",
      "tensor(642055.3750, grad_fn=<AddBackward0>) tensor(204.7174, grad_fn=<SumBackward0>)\n",
      "tensor(667246.5625, grad_fn=<AddBackward0>) tensor(212.6812, grad_fn=<SumBackward0>)\n",
      "tensor(685639.6250, grad_fn=<AddBackward0>) tensor(218.5030, grad_fn=<SumBackward0>)\n",
      "tensor(683357.1250, grad_fn=<AddBackward0>) tensor(217.7777, grad_fn=<SumBackward0>)\n",
      "tensor(668315.6250, grad_fn=<AddBackward0>) tensor(213.0092, grad_fn=<SumBackward0>)\n",
      "tensor(677796., grad_fn=<AddBackward0>) tensor(216.0166, grad_fn=<SumBackward0>)\n",
      "tensor(705980.2500, grad_fn=<AddBackward0>) tensor(224.9418, grad_fn=<SumBackward0>)\n",
      "tensor(656276., grad_fn=<AddBackward0>) tensor(209.1852, grad_fn=<SumBackward0>)\n",
      "tensor(679895.2500, grad_fn=<AddBackward0>) tensor(216.7010, grad_fn=<SumBackward0>)\n",
      "tensor(661942.8750, grad_fn=<AddBackward0>) tensor(210.9778, grad_fn=<SumBackward0>)\n",
      "tensor(682708.7500, grad_fn=<AddBackward0>) tensor(217.5658, grad_fn=<SumBackward0>)\n",
      "tensor(693837., grad_fn=<AddBackward0>) tensor(221.1050, grad_fn=<SumBackward0>)\n",
      "tensor(698855.8750, grad_fn=<AddBackward0>) tensor(222.6823, grad_fn=<SumBackward0>)\n",
      "tensor(682083.6875, grad_fn=<AddBackward0>) tensor(217.3708, grad_fn=<SumBackward0>)\n",
      "tensor(671498.3750, grad_fn=<AddBackward0>) tensor(214.0035, grad_fn=<SumBackward0>)\n",
      "tensor(689179.6250, grad_fn=<AddBackward0>) tensor(219.6129, grad_fn=<SumBackward0>)\n",
      "tensor(683918.3125, grad_fn=<AddBackward0>) tensor(217.9393, grad_fn=<SumBackward0>)\n",
      "tensor(686730.6250, grad_fn=<AddBackward0>) tensor(218.8286, grad_fn=<SumBackward0>)\n",
      "tensor(627704.3750, grad_fn=<AddBackward0>) tensor(200.1412, grad_fn=<SumBackward0>)\n",
      "tensor(703933.3750, grad_fn=<AddBackward0>) tensor(224.3130, grad_fn=<SumBackward0>)\n",
      "tensor(681647.5000, grad_fn=<AddBackward0>) tensor(217.2275, grad_fn=<SumBackward0>)\n",
      "tensor(667340.8750, grad_fn=<AddBackward0>) tensor(212.7040, grad_fn=<SumBackward0>)\n",
      "tensor(701090.5000, grad_fn=<AddBackward0>) tensor(223.3742, grad_fn=<SumBackward0>)\n",
      "tensor(692320.5625, grad_fn=<AddBackward0>) tensor(220.6230, grad_fn=<SumBackward0>)\n",
      "tensor(660080.1875, grad_fn=<AddBackward0>) tensor(210.3757, grad_fn=<SumBackward0>)\n",
      "tensor(666553.4375, grad_fn=<AddBackward0>) tensor(212.4443, grad_fn=<SumBackward0>)\n",
      "tensor(664885.8125, grad_fn=<AddBackward0>) tensor(211.9196, grad_fn=<SumBackward0>)\n",
      "tensor(657044.6875, grad_fn=<AddBackward0>) tensor(209.4236, grad_fn=<SumBackward0>)\n",
      "tensor(679573.3750, grad_fn=<AddBackward0>) tensor(216.5723, grad_fn=<SumBackward0>)\n",
      "tensor(670471., grad_fn=<AddBackward0>) tensor(213.6908, grad_fn=<SumBackward0>)\n",
      "tensor(651042.6250, grad_fn=<AddBackward0>) tensor(207.5446, grad_fn=<SumBackward0>)\n",
      "tensor(714107.0625, grad_fn=<AddBackward0>) tensor(227.5098, grad_fn=<SumBackward0>)\n",
      "tensor(684966.2500, grad_fn=<AddBackward0>) tensor(218.2887, grad_fn=<SumBackward0>)\n",
      "tensor(656658.8750, grad_fn=<AddBackward0>) tensor(209.2982, grad_fn=<SumBackward0>)\n",
      "tensor(693746.5625, grad_fn=<AddBackward0>) tensor(221.0352, grad_fn=<SumBackward0>)\n",
      "tensor(681266.1875, grad_fn=<AddBackward0>) tensor(217.0934, grad_fn=<SumBackward0>)\n",
      "tensor(656778.2500, grad_fn=<AddBackward0>) tensor(209.3528, grad_fn=<SumBackward0>)\n",
      "tensor(680096.8125, grad_fn=<AddBackward0>) tensor(216.7240, grad_fn=<SumBackward0>)\n",
      "tensor(688947.6250, grad_fn=<AddBackward0>) tensor(219.5201, grad_fn=<SumBackward0>)\n",
      "tensor(674427., grad_fn=<AddBackward0>) tensor(214.9444, grad_fn=<SumBackward0>)\n",
      "tensor(641696.5625, grad_fn=<AddBackward0>) tensor(204.5692, grad_fn=<SumBackward0>)\n",
      "tensor(684989.9375, grad_fn=<AddBackward0>) tensor(218.2742, grad_fn=<SumBackward0>)\n",
      "tensor(657967.5000, grad_fn=<AddBackward0>) tensor(209.7206, grad_fn=<SumBackward0>)\n",
      "tensor(664707.4375, grad_fn=<AddBackward0>) tensor(211.8615, grad_fn=<SumBackward0>)\n",
      "tensor(706468.8125, grad_fn=<AddBackward0>) tensor(225.0922, grad_fn=<SumBackward0>)\n",
      "tensor(696812.8750, grad_fn=<AddBackward0>) tensor(222.0112, grad_fn=<SumBackward0>)\n",
      "tensor(669836.8750, grad_fn=<AddBackward0>) tensor(213.4725, grad_fn=<SumBackward0>)\n",
      "tensor(687849., grad_fn=<AddBackward0>) tensor(219.1883, grad_fn=<SumBackward0>)\n",
      "tensor(674110.9375, grad_fn=<AddBackward0>) tensor(214.8243, grad_fn=<SumBackward0>)\n",
      "tensor(659168.6250, grad_fn=<AddBackward0>) tensor(210.0749, grad_fn=<SumBackward0>)\n",
      "tensor(641718.5625, grad_fn=<AddBackward0>) tensor(204.5562, grad_fn=<SumBackward0>)\n",
      "tensor(663146.8125, grad_fn=<AddBackward0>) tensor(211.3508, grad_fn=<SumBackward0>)\n",
      "tensor(675127.9375, grad_fn=<AddBackward0>) tensor(215.1281, grad_fn=<SumBackward0>)\n",
      "tensor(638447.7500, grad_fn=<AddBackward0>) tensor(203.5266, grad_fn=<SumBackward0>)\n",
      "tensor(696932.5625, grad_fn=<AddBackward0>) tensor(222.0251, grad_fn=<SumBackward0>)\n",
      "tensor(658045.2500, grad_fn=<AddBackward0>) tensor(209.7251, grad_fn=<SumBackward0>)\n",
      "tensor(655842.3125, grad_fn=<AddBackward0>) tensor(209.0418, grad_fn=<SumBackward0>)\n",
      "tensor(691933.7500, grad_fn=<AddBackward0>) tensor(220.4607, grad_fn=<SumBackward0>)\n",
      "tensor(669332.5625, grad_fn=<AddBackward0>) tensor(213.2937, grad_fn=<SumBackward0>)\n",
      "tensor(637237.5625, grad_fn=<AddBackward0>) tensor(203.1369, grad_fn=<SumBackward0>)\n",
      "tensor(685727.7500, grad_fn=<AddBackward0>) tensor(218.4780, grad_fn=<SumBackward0>)\n",
      "tensor(681365.8750, grad_fn=<AddBackward0>) tensor(217.1190, grad_fn=<SumBackward0>)\n",
      "tensor(678814., grad_fn=<AddBackward0>) tensor(216.2761, grad_fn=<SumBackward0>)\n",
      "tensor(676349.1875, grad_fn=<AddBackward0>) tensor(215.5092, grad_fn=<SumBackward0>)\n",
      "tensor(678796.7500, grad_fn=<AddBackward0>) tensor(216.3041, grad_fn=<SumBackward0>)\n",
      "tensor(696317., grad_fn=<AddBackward0>) tensor(221.8225, grad_fn=<SumBackward0>)\n",
      "tensor(694987.9375, grad_fn=<AddBackward0>) tensor(221.4139, grad_fn=<SumBackward0>)\n",
      "tensor(645245.5625, grad_fn=<AddBackward0>) tensor(205.6335, grad_fn=<SumBackward0>)\n",
      "tensor(674148.3750, grad_fn=<AddBackward0>) tensor(214.7678, grad_fn=<SumBackward0>)\n",
      "tensor(657192.8125, grad_fn=<AddBackward0>) tensor(209.4313, grad_fn=<SumBackward0>)\n",
      "tensor(649412.9375, grad_fn=<AddBackward0>) tensor(206.9681, grad_fn=<SumBackward0>)\n",
      "tensor(644448.4375, grad_fn=<AddBackward0>) tensor(205.3849, grad_fn=<SumBackward0>)\n",
      "tensor(638322.8125, grad_fn=<AddBackward0>) tensor(203.4602, grad_fn=<SumBackward0>)\n",
      "tensor(648453.1250, grad_fn=<AddBackward0>) tensor(206.6734, grad_fn=<SumBackward0>)\n",
      "tensor(645734.4375, grad_fn=<AddBackward0>) tensor(205.7994, grad_fn=<SumBackward0>)\n",
      "tensor(670874.9375, grad_fn=<AddBackward0>) tensor(213.7564, grad_fn=<SumBackward0>)\n",
      "tensor(691396.2500, grad_fn=<AddBackward0>) tensor(220.2677, grad_fn=<SumBackward0>)\n",
      "tensor(660112.9375, grad_fn=<AddBackward0>) tensor(210.3466, grad_fn=<SumBackward0>)\n",
      "tensor(651895.8750, grad_fn=<AddBackward0>) tensor(207.7262, grad_fn=<SumBackward0>)\n",
      "tensor(664857.1250, grad_fn=<AddBackward0>) tensor(211.8329, grad_fn=<SumBackward0>)\n",
      "tensor(657717.1875, grad_fn=<AddBackward0>) tensor(209.5871, grad_fn=<SumBackward0>)\n",
      "tensor(691926., grad_fn=<AddBackward0>) tensor(220.4107, grad_fn=<SumBackward0>)\n",
      "tensor(661209.3125, grad_fn=<AddBackward0>) tensor(210.6841, grad_fn=<SumBackward0>)\n",
      "tensor(649657.2500, grad_fn=<AddBackward0>) tensor(207.0338, grad_fn=<SumBackward0>)\n",
      "tensor(657901.5000, grad_fn=<AddBackward0>) tensor(209.6390, grad_fn=<SumBackward0>)\n",
      "tensor(639172.0625, grad_fn=<AddBackward0>) tensor(203.6945, grad_fn=<SumBackward0>)\n",
      "tensor(660991.5000, grad_fn=<AddBackward0>) tensor(210.5981, grad_fn=<SumBackward0>)\n",
      "tensor(648762., grad_fn=<AddBackward0>) tensor(206.7333, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(647510.0625, grad_fn=<AddBackward0>) tensor(206.3195, grad_fn=<SumBackward0>)\n",
      "tensor(647541.7500, grad_fn=<AddBackward0>) tensor(206.3565, grad_fn=<SumBackward0>)\n",
      "tensor(649638.5000, grad_fn=<AddBackward0>) tensor(207.0047, grad_fn=<SumBackward0>)\n",
      "tensor(681393.5625, grad_fn=<AddBackward0>) tensor(217.0705, grad_fn=<SumBackward0>)\n",
      "tensor(670561.8750, grad_fn=<AddBackward0>) tensor(213.6316, grad_fn=<SumBackward0>)\n",
      "tensor(646760.0625, grad_fn=<AddBackward0>) tensor(206.0765, grad_fn=<SumBackward0>)\n",
      "tensor(673011.6875, grad_fn=<AddBackward0>) tensor(214.3960, grad_fn=<SumBackward0>)\n",
      "tensor(644005.1875, grad_fn=<AddBackward0>) tensor(205.1999, grad_fn=<SumBackward0>)\n",
      "tensor(667657.2500, grad_fn=<AddBackward0>) tensor(212.6836, grad_fn=<SumBackward0>)\n",
      "tensor(643888.0625, grad_fn=<AddBackward0>) tensor(205.2027, grad_fn=<SumBackward0>)\n",
      "tensor(668689.8750, grad_fn=<AddBackward0>) tensor(213.0445, grad_fn=<SumBackward0>)\n",
      "tensor(686717.6875, grad_fn=<AddBackward0>) tensor(218.7411, grad_fn=<SumBackward0>)\n",
      "tensor(652293.5625, grad_fn=<AddBackward0>) tensor(207.8226, grad_fn=<SumBackward0>)\n",
      "tensor(672055.0625, grad_fn=<AddBackward0>) tensor(214.0733, grad_fn=<SumBackward0>)\n",
      "tensor(658195.8750, grad_fn=<AddBackward0>) tensor(209.6783, grad_fn=<SumBackward0>)\n",
      "tensor(629508.3750, grad_fn=<AddBackward0>) tensor(200.6038, grad_fn=<SumBackward0>)\n",
      "tensor(638821.3750, grad_fn=<AddBackward0>) tensor(203.5366, grad_fn=<SumBackward0>)\n",
      "tensor(635126.3750, grad_fn=<AddBackward0>) tensor(202.3544, grad_fn=<SumBackward0>)\n",
      "tensor(664635., grad_fn=<AddBackward0>) tensor(211.7408, grad_fn=<SumBackward0>)\n",
      "tensor(661531.6250, grad_fn=<AddBackward0>) tensor(210.7316, grad_fn=<SumBackward0>)\n",
      "tensor(658336.8750, grad_fn=<AddBackward0>) tensor(209.7228, grad_fn=<SumBackward0>)\n",
      "tensor(649688.2500, grad_fn=<AddBackward0>) tensor(206.9790, grad_fn=<SumBackward0>)\n",
      "tensor(636630.2500, grad_fn=<AddBackward0>) tensor(202.8385, grad_fn=<SumBackward0>)\n",
      "tensor(607959.8750, grad_fn=<AddBackward0>) tensor(193.7371, grad_fn=<SumBackward0>)\n",
      "tensor(625786.8750, grad_fn=<AddBackward0>) tensor(199.4223, grad_fn=<SumBackward0>)\n",
      "tensor(638352.6875, grad_fn=<AddBackward0>) tensor(203.3917, grad_fn=<SumBackward0>)\n",
      "tensor(665109.0625, grad_fn=<AddBackward0>) tensor(211.8595, grad_fn=<SumBackward0>)\n",
      "tensor(653538.5000, grad_fn=<AddBackward0>) tensor(208.1623, grad_fn=<SumBackward0>)\n",
      "tensor(639280.4375, grad_fn=<AddBackward0>) tensor(203.6686, grad_fn=<SumBackward0>)\n",
      "tensor(629878.8750, grad_fn=<AddBackward0>) tensor(200.6512, grad_fn=<SumBackward0>)\n",
      "tensor(644658.6250, grad_fn=<AddBackward0>) tensor(205.3750, grad_fn=<SumBackward0>)\n",
      "tensor(638325.8750, grad_fn=<AddBackward0>) tensor(203.3370, grad_fn=<SumBackward0>)\n",
      "tensor(606733.4375, grad_fn=<AddBackward0>) tensor(193.3356, grad_fn=<SumBackward0>)\n",
      "tensor(636603.0625, grad_fn=<AddBackward0>) tensor(202.7993, grad_fn=<SumBackward0>)\n",
      "tensor(606039.2500, grad_fn=<AddBackward0>) tensor(193.1005, grad_fn=<SumBackward0>)\n",
      "tensor(619648.5625, grad_fn=<AddBackward0>) tensor(197.3930, grad_fn=<SumBackward0>)\n",
      "tensor(677860.4375, grad_fn=<AddBackward0>) tensor(215.8250, grad_fn=<SumBackward0>)\n",
      "tensor(639875.6250, grad_fn=<AddBackward0>) tensor(203.7893, grad_fn=<SumBackward0>)\n",
      "tensor(641565.3125, grad_fn=<AddBackward0>) tensor(204.3342, grad_fn=<SumBackward0>)\n",
      "tensor(640900.5000, grad_fn=<AddBackward0>) tensor(204.1398, grad_fn=<SumBackward0>)\n",
      "tensor(620715.1875, grad_fn=<AddBackward0>) tensor(197.6988, grad_fn=<SumBackward0>)\n",
      "tensor(606460.1875, grad_fn=<AddBackward0>) tensor(193.1839, grad_fn=<SumBackward0>)\n",
      "tensor(629009.6875, grad_fn=<AddBackward0>) tensor(200.3181, grad_fn=<SumBackward0>)\n",
      "tensor(628784.3125, grad_fn=<AddBackward0>) tensor(200.2485, grad_fn=<SumBackward0>)\n",
      "tensor(638891.5625, grad_fn=<AddBackward0>) tensor(203.4490, grad_fn=<SumBackward0>)\n",
      "tensor(646766.6875, grad_fn=<AddBackward0>) tensor(205.9615, grad_fn=<SumBackward0>)\n",
      "tensor(597598.6250, grad_fn=<AddBackward0>) tensor(190.3262, grad_fn=<SumBackward0>)\n",
      "tensor(601933.3750, grad_fn=<AddBackward0>) tensor(191.7116, grad_fn=<SumBackward0>)\n",
      "tensor(633134.5625, grad_fn=<AddBackward0>) tensor(201.5985, grad_fn=<SumBackward0>)\n",
      "tensor(620353.3750, grad_fn=<AddBackward0>) tensor(197.5706, grad_fn=<SumBackward0>)\n",
      "tensor(644967.5625, grad_fn=<AddBackward0>) tensor(205.3109, grad_fn=<SumBackward0>)\n",
      "tensor(616276.8125, grad_fn=<AddBackward0>) tensor(196.2005, grad_fn=<SumBackward0>)\n",
      "tensor(618414.4375, grad_fn=<AddBackward0>) tensor(196.9042, grad_fn=<SumBackward0>)\n",
      "tensor(618938.0625, grad_fn=<AddBackward0>) tensor(197.0635, grad_fn=<SumBackward0>)\n",
      "tensor(613645.4375, grad_fn=<AddBackward0>) tensor(195.3891, grad_fn=<SumBackward0>)\n",
      "tensor(625014.7500, grad_fn=<AddBackward0>) tensor(198.9729, grad_fn=<SumBackward0>)\n",
      "tensor(628696.1875, grad_fn=<AddBackward0>) tensor(200.1258, grad_fn=<SumBackward0>)\n",
      "tensor(629204.3125, grad_fn=<AddBackward0>) tensor(200.2709, grad_fn=<SumBackward0>)\n",
      "tensor(636296.0625, grad_fn=<AddBackward0>) tensor(202.5006, grad_fn=<SumBackward0>)\n",
      "tensor(617017.8125, grad_fn=<AddBackward0>) tensor(196.3918, grad_fn=<SumBackward0>)\n",
      "tensor(606966.1250, grad_fn=<AddBackward0>) tensor(193.1726, grad_fn=<SumBackward0>)\n",
      "tensor(604765.6250, grad_fn=<AddBackward0>) tensor(192.4800, grad_fn=<SumBackward0>)\n",
      "tensor(591293.2500, grad_fn=<AddBackward0>) tensor(188.1880, grad_fn=<SumBackward0>)\n",
      "tensor(592562.6250, grad_fn=<AddBackward0>) tensor(188.5796, grad_fn=<SumBackward0>)\n",
      "tensor(614112.3125, grad_fn=<AddBackward0>) tensor(195.3677, grad_fn=<SumBackward0>)\n",
      "tensor(597845.7500, grad_fn=<AddBackward0>) tensor(190.1621, grad_fn=<SumBackward0>)\n",
      "tensor(586762.1875, grad_fn=<AddBackward0>) tensor(186.7021, grad_fn=<SumBackward0>)\n",
      "tensor(581973.6875, grad_fn=<AddBackward0>) tensor(185.1663, grad_fn=<SumBackward0>)\n",
      "tensor(611619.5625, grad_fn=<AddBackward0>) tensor(194.5312, grad_fn=<SumBackward0>)\n",
      "tensor(607374.7500, grad_fn=<AddBackward0>) tensor(193.1739, grad_fn=<SumBackward0>)\n",
      "tensor(609479., grad_fn=<AddBackward0>) tensor(193.8016, grad_fn=<SumBackward0>)\n",
      "tensor(584456.8125, grad_fn=<AddBackward0>) tensor(185.8610, grad_fn=<SumBackward0>)\n",
      "tensor(581843.7500, grad_fn=<AddBackward0>) tensor(184.9696, grad_fn=<SumBackward0>)\n",
      "tensor(590850.5625, grad_fn=<AddBackward0>) tensor(187.8027, grad_fn=<SumBackward0>)\n",
      "tensor(568265.6875, grad_fn=<AddBackward0>) tensor(180.6152, grad_fn=<SumBackward0>)\n",
      "tensor(586449.5000, grad_fn=<AddBackward0>) tensor(186.3855, grad_fn=<SumBackward0>)\n",
      "tensor(558163.1875, grad_fn=<AddBackward0>) tensor(177.3625, grad_fn=<SumBackward0>)\n",
      "tensor(576525.1875, grad_fn=<AddBackward0>) tensor(183.1504, grad_fn=<SumBackward0>)\n",
      "tensor(592150.1250, grad_fn=<AddBackward0>) tensor(188.0864, grad_fn=<SumBackward0>)\n",
      "tensor(565830.3750, grad_fn=<AddBackward0>) tensor(179.6469, grad_fn=<SumBackward0>)\n",
      "tensor(558494.6250, grad_fn=<AddBackward0>) tensor(177.2595, grad_fn=<SumBackward0>)\n",
      "tensor(559709.1875, grad_fn=<AddBackward0>) tensor(177.5398, grad_fn=<SumBackward0>)\n",
      "tensor(573493.2500, grad_fn=<AddBackward0>) tensor(181.9237, grad_fn=<SumBackward0>)\n",
      "tensor(542020.6250, grad_fn=<AddBackward0>) tensor(171.8823, grad_fn=<SumBackward0>)\n",
      "tensor(567766.6875, grad_fn=<AddBackward0>) tensor(179.9395, grad_fn=<SumBackward0>)\n",
      "tensor(527829.6250, grad_fn=<AddBackward0>) tensor(167.2720, grad_fn=<SumBackward0>)\n",
      "tensor(541348.5000, grad_fn=<AddBackward0>) tensor(171.4356, grad_fn=<SumBackward0>)\n",
      "tensor(555499.3750, grad_fn=<AddBackward0>) tensor(175.6541, grad_fn=<SumBackward0>)\n",
      "tensor(538889.9375, grad_fn=<AddBackward0>) tensor(170.3529, grad_fn=<SumBackward0>)\n",
      "tensor(567981.5000, grad_fn=<AddBackward0>) tensor(179.6488, grad_fn=<SumBackward0>)\n",
      "tensor(528804.6250, grad_fn=<AddBackward0>) tensor(167.0210, grad_fn=<SumBackward0>)\n",
      "tensor(531364.3750, grad_fn=<AddBackward0>) tensor(167.7296, grad_fn=<SumBackward0>)\n",
      "tensor(549776.9375, grad_fn=<AddBackward0>) tensor(173.3407, grad_fn=<SumBackward0>)\n",
      "tensor(568899.8750, grad_fn=<AddBackward0>) tensor(179.2677, grad_fn=<SumBackward0>)\n",
      "tensor(540575., grad_fn=<AddBackward0>) tensor(170.2169, grad_fn=<SumBackward0>)\n",
      "tensor(559078.5625, grad_fn=<AddBackward0>) tensor(175.7865, grad_fn=<SumBackward0>)\n",
      "tensor(535040.1250, grad_fn=<AddBackward0>) tensor(168.3577, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(537738., grad_fn=<AddBackward0>) tensor(169.0965, grad_fn=<SumBackward0>)\n",
      "tensor(577483.3125, grad_fn=<AddBackward0>) tensor(181.6254, grad_fn=<SumBackward0>)\n",
      "tensor(551067., grad_fn=<AddBackward0>) tensor(173.4243, grad_fn=<SumBackward0>)\n",
      "tensor(612607.6250, grad_fn=<AddBackward0>) tensor(192.5208, grad_fn=<SumBackward0>)\n",
      "tensor(562516.6250, grad_fn=<AddBackward0>) tensor(177.2191, grad_fn=<SumBackward0>)\n",
      "tensor(547503.2500, grad_fn=<AddBackward0>) tensor(172.4715, grad_fn=<SumBackward0>)\n",
      "tensor(550957.3125, grad_fn=<AddBackward0>) tensor(173.8830, grad_fn=<SumBackward0>)\n",
      "tensor(551321.1875, grad_fn=<AddBackward0>) tensor(173.9652, grad_fn=<SumBackward0>)\n",
      "tensor(527857.6875, grad_fn=<AddBackward0>) tensor(166.5405, grad_fn=<SumBackward0>)\n",
      "tensor(562620.5625, grad_fn=<AddBackward0>) tensor(177.6690, grad_fn=<SumBackward0>)\n",
      "tensor(540362.1875, grad_fn=<AddBackward0>) tensor(170.7261, grad_fn=<SumBackward0>)\n",
      "tensor(562123.1250, grad_fn=<AddBackward0>) tensor(177.5763, grad_fn=<SumBackward0>)\n",
      "tensor(554359.8750, grad_fn=<AddBackward0>) tensor(175.2106, grad_fn=<SumBackward0>)\n",
      "tensor(571439.0625, grad_fn=<AddBackward0>) tensor(180.4298, grad_fn=<SumBackward0>)\n",
      "tensor(552207.1250, grad_fn=<AddBackward0>) tensor(174.6142, grad_fn=<SumBackward0>)\n",
      "tensor(554339.1875, grad_fn=<AddBackward0>) tensor(175.1483, grad_fn=<SumBackward0>)\n",
      "tensor(562660.5625, grad_fn=<AddBackward0>) tensor(177.9902, grad_fn=<SumBackward0>)\n",
      "tensor(533648.3750, grad_fn=<AddBackward0>) tensor(168.7558, grad_fn=<SumBackward0>)\n",
      "tensor(541680.6250, grad_fn=<AddBackward0>) tensor(171.3790, grad_fn=<SumBackward0>)\n",
      "tensor(558544.8750, grad_fn=<AddBackward0>) tensor(176.7245, grad_fn=<SumBackward0>)\n",
      "tensor(525585.2500, grad_fn=<AddBackward0>) tensor(166.3111, grad_fn=<SumBackward0>)\n",
      "tensor(566644., grad_fn=<AddBackward0>) tensor(179.2335, grad_fn=<SumBackward0>)\n",
      "tensor(543698.3750, grad_fn=<AddBackward0>) tensor(171.9871, grad_fn=<SumBackward0>)\n",
      "tensor(533462.4375, grad_fn=<AddBackward0>) tensor(168.6578, grad_fn=<SumBackward0>)\n",
      "tensor(523865.8750, grad_fn=<AddBackward0>) tensor(165.6678, grad_fn=<SumBackward0>)\n",
      "tensor(547301.1875, grad_fn=<AddBackward0>) tensor(173.0855, grad_fn=<SumBackward0>)\n",
      "tensor(551468.8750, grad_fn=<AddBackward0>) tensor(174.2722, grad_fn=<SumBackward0>)\n",
      "tensor(551669.5000, grad_fn=<AddBackward0>) tensor(174.3870, grad_fn=<SumBackward0>)\n",
      "tensor(540495.5625, grad_fn=<AddBackward0>) tensor(170.7796, grad_fn=<SumBackward0>)\n",
      "tensor(546863., grad_fn=<AddBackward0>) tensor(172.9950, grad_fn=<SumBackward0>)\n",
      "tensor(519189., grad_fn=<AddBackward0>) tensor(164.0788, grad_fn=<SumBackward0>)\n",
      "tensor(535653.8750, grad_fn=<AddBackward0>) tensor(169.3115, grad_fn=<SumBackward0>)\n",
      "tensor(531678.7500, grad_fn=<AddBackward0>) tensor(167.9830, grad_fn=<SumBackward0>)\n",
      "tensor(530808.5625, grad_fn=<AddBackward0>) tensor(167.7776, grad_fn=<SumBackward0>)\n",
      "tensor(532779.1875, grad_fn=<AddBackward0>) tensor(168.1968, grad_fn=<SumBackward0>)\n",
      "tensor(551074.8750, grad_fn=<AddBackward0>) tensor(174.0594, grad_fn=<SumBackward0>)\n",
      "tensor(554085.5000, grad_fn=<AddBackward0>) tensor(174.9478, grad_fn=<SumBackward0>)\n",
      "tensor(569305.8125, grad_fn=<AddBackward0>) tensor(179.7576, grad_fn=<SumBackward0>)\n",
      "tensor(556167.3750, grad_fn=<AddBackward0>) tensor(175.6825, grad_fn=<SumBackward0>)\n",
      "tensor(511865.9375, grad_fn=<AddBackward0>) tensor(161.5701, grad_fn=<SumBackward0>)\n",
      "tensor(528549.6250, grad_fn=<AddBackward0>) tensor(166.8016, grad_fn=<SumBackward0>)\n",
      "tensor(564939.5000, grad_fn=<AddBackward0>) tensor(178.2826, grad_fn=<SumBackward0>)\n",
      "tensor(518445.3750, grad_fn=<AddBackward0>) tensor(163.6732, grad_fn=<SumBackward0>)\n",
      "tensor(553710.8125, grad_fn=<AddBackward0>) tensor(174.6798, grad_fn=<SumBackward0>)\n",
      "tensor(537058., grad_fn=<AddBackward0>) tensor(169.4850, grad_fn=<SumBackward0>)\n",
      "tensor(530752.8125, grad_fn=<AddBackward0>) tensor(167.4963, grad_fn=<SumBackward0>)\n",
      "tensor(550167.8125, grad_fn=<AddBackward0>) tensor(173.7271, grad_fn=<SumBackward0>)\n",
      "tensor(534219.6250, grad_fn=<AddBackward0>) tensor(168.6164, grad_fn=<SumBackward0>)\n",
      "tensor(518512.4062, grad_fn=<AddBackward0>) tensor(163.5927, grad_fn=<SumBackward0>)\n",
      "tensor(549708.2500, grad_fn=<AddBackward0>) tensor(173.5737, grad_fn=<SumBackward0>)\n",
      "tensor(549398.5625, grad_fn=<AddBackward0>) tensor(173.4471, grad_fn=<SumBackward0>)\n",
      "tensor(531012.4375, grad_fn=<AddBackward0>) tensor(167.5853, grad_fn=<SumBackward0>)\n",
      "tensor(536186.4375, grad_fn=<AddBackward0>) tensor(169.1924, grad_fn=<SumBackward0>)\n",
      "tensor(576842.5625, grad_fn=<AddBackward0>) tensor(182.0309, grad_fn=<SumBackward0>)\n",
      "tensor(516865.2188, grad_fn=<AddBackward0>) tensor(163.0999, grad_fn=<SumBackward0>)\n",
      "tensor(585405.6250, grad_fn=<AddBackward0>) tensor(184.6466, grad_fn=<SumBackward0>)\n",
      "tensor(557557.5000, grad_fn=<AddBackward0>) tensor(176.0008, grad_fn=<SumBackward0>)\n",
      "tensor(521767.4062, grad_fn=<AddBackward0>) tensor(164.7547, grad_fn=<SumBackward0>)\n",
      "tensor(550588.6875, grad_fn=<AddBackward0>) tensor(173.8684, grad_fn=<SumBackward0>)\n",
      "tensor(526204.2500, grad_fn=<AddBackward0>) tensor(166.1793, grad_fn=<SumBackward0>)\n",
      "tensor(537004.8750, grad_fn=<AddBackward0>) tensor(169.4348, grad_fn=<SumBackward0>)\n",
      "tensor(530337.5625, grad_fn=<AddBackward0>) tensor(167.5392, grad_fn=<SumBackward0>)\n",
      "tensor(537911.6875, grad_fn=<AddBackward0>) tensor(169.9556, grad_fn=<SumBackward0>)\n",
      "tensor(538492.4375, grad_fn=<AddBackward0>) tensor(170.0403, grad_fn=<SumBackward0>)\n",
      "tensor(541099.2500, grad_fn=<AddBackward0>) tensor(170.8902, grad_fn=<SumBackward0>)\n",
      "tensor(525522.1875, grad_fn=<AddBackward0>) tensor(165.9344, grad_fn=<SumBackward0>)\n",
      "tensor(542788.4375, grad_fn=<AddBackward0>) tensor(171.3321, grad_fn=<SumBackward0>)\n",
      "tensor(536692.1875, grad_fn=<AddBackward0>) tensor(169.4223, grad_fn=<SumBackward0>)\n",
      "tensor(553866., grad_fn=<AddBackward0>) tensor(174.7399, grad_fn=<SumBackward0>)\n",
      "tensor(523603.3750, grad_fn=<AddBackward0>) tensor(165.2353, grad_fn=<SumBackward0>)\n",
      "tensor(556960.9375, grad_fn=<AddBackward0>) tensor(175.7197, grad_fn=<SumBackward0>)\n",
      "tensor(507559.3125, grad_fn=<AddBackward0>) tensor(160.2811, grad_fn=<SumBackward0>)\n",
      "tensor(539111.8125, grad_fn=<AddBackward0>) tensor(170.2101, grad_fn=<SumBackward0>)\n",
      "tensor(510520.2500, grad_fn=<AddBackward0>) tensor(161.1018, grad_fn=<SumBackward0>)\n",
      "tensor(528149.1250, grad_fn=<AddBackward0>) tensor(166.7287, grad_fn=<SumBackward0>)\n",
      "tensor(507240.4062, grad_fn=<AddBackward0>) tensor(160.0648, grad_fn=<SumBackward0>)\n",
      "tensor(520143.5625, grad_fn=<AddBackward0>) tensor(164.0954, grad_fn=<SumBackward0>)\n",
      "tensor(545623.0625, grad_fn=<AddBackward0>) tensor(172.3474, grad_fn=<SumBackward0>)\n",
      "tensor(513307.1562, grad_fn=<AddBackward0>) tensor(162.0053, grad_fn=<SumBackward0>)\n",
      "tensor(494662.9688, grad_fn=<AddBackward0>) tensor(156.1284, grad_fn=<SumBackward0>)\n",
      "tensor(527538.1250, grad_fn=<AddBackward0>) tensor(166.3956, grad_fn=<SumBackward0>)\n",
      "tensor(520077.7500, grad_fn=<AddBackward0>) tensor(164.1281, grad_fn=<SumBackward0>)\n",
      "tensor(505658.7500, grad_fn=<AddBackward0>) tensor(159.4598, grad_fn=<SumBackward0>)\n",
      "tensor(499289.5000, grad_fn=<AddBackward0>) tensor(157.2481, grad_fn=<SumBackward0>)\n",
      "tensor(531678.5625, grad_fn=<AddBackward0>) tensor(167.5538, grad_fn=<SumBackward0>)\n",
      "tensor(523110.2812, grad_fn=<AddBackward0>) tensor(164.8954, grad_fn=<SumBackward0>)\n",
      "tensor(542053.4375, grad_fn=<AddBackward0>) tensor(170.8724, grad_fn=<SumBackward0>)\n",
      "tensor(517113.8750, grad_fn=<AddBackward0>) tensor(162.9915, grad_fn=<SumBackward0>)\n",
      "tensor(514449.5000, grad_fn=<AddBackward0>) tensor(162.1345, grad_fn=<SumBackward0>)\n",
      "tensor(517827.8125, grad_fn=<AddBackward0>) tensor(163.2193, grad_fn=<SumBackward0>)\n",
      "tensor(545861.6875, grad_fn=<AddBackward0>) tensor(171.8159, grad_fn=<SumBackward0>)\n",
      "tensor(554898.3750, grad_fn=<AddBackward0>) tensor(174.7072, grad_fn=<SumBackward0>)\n",
      "tensor(530804.2500, grad_fn=<AddBackward0>) tensor(167.3426, grad_fn=<SumBackward0>)\n",
      "tensor(523063.6875, grad_fn=<AddBackward0>) tensor(164.8969, grad_fn=<SumBackward0>)\n",
      "tensor(507594.6562, grad_fn=<AddBackward0>) tensor(159.9303, grad_fn=<SumBackward0>)\n",
      "tensor(545548.0625, grad_fn=<AddBackward0>) tensor(172.0865, grad_fn=<SumBackward0>)\n",
      "tensor(517169.3750, grad_fn=<AddBackward0>) tensor(163.0564, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(499023.8750, grad_fn=<AddBackward0>) tensor(157.3339, grad_fn=<SumBackward0>)\n",
      "tensor(516590.2812, grad_fn=<AddBackward0>) tensor(162.8741, grad_fn=<SumBackward0>)\n",
      "tensor(532953.5000, grad_fn=<AddBackward0>) tensor(167.9922, grad_fn=<SumBackward0>)\n",
      "tensor(527891.6250, grad_fn=<AddBackward0>) tensor(166.4652, grad_fn=<SumBackward0>)\n",
      "tensor(522769.1562, grad_fn=<AddBackward0>) tensor(164.9516, grad_fn=<SumBackward0>)\n",
      "tensor(515532.4688, grad_fn=<AddBackward0>) tensor(162.7191, grad_fn=<SumBackward0>)\n",
      "tensor(511187.6875, grad_fn=<AddBackward0>) tensor(161.1781, grad_fn=<SumBackward0>)\n",
      "tensor(523136.8438, grad_fn=<AddBackward0>) tensor(164.9557, grad_fn=<SumBackward0>)\n",
      "tensor(515922.5000, grad_fn=<AddBackward0>) tensor(162.6273, grad_fn=<SumBackward0>)\n",
      "tensor(534572.6875, grad_fn=<AddBackward0>) tensor(168.8588, grad_fn=<SumBackward0>)\n",
      "tensor(512893.5312, grad_fn=<AddBackward0>) tensor(161.8757, grad_fn=<SumBackward0>)\n",
      "tensor(519493.5938, grad_fn=<AddBackward0>) tensor(163.9362, grad_fn=<SumBackward0>)\n",
      "tensor(514646.6875, grad_fn=<AddBackward0>) tensor(162.4046, grad_fn=<SumBackward0>)\n",
      "tensor(517268.2500, grad_fn=<AddBackward0>) tensor(163.0465, grad_fn=<SumBackward0>)\n",
      "tensor(527922.4375, grad_fn=<AddBackward0>) tensor(166.5693, grad_fn=<SumBackward0>)\n",
      "tensor(525622., grad_fn=<AddBackward0>) tensor(165.8638, grad_fn=<SumBackward0>)\n",
      "tensor(513686.5312, grad_fn=<AddBackward0>) tensor(161.9863, grad_fn=<SumBackward0>)\n",
      "tensor(520734.3750, grad_fn=<AddBackward0>) tensor(164.2106, grad_fn=<SumBackward0>)\n",
      "tensor(519379.7188, grad_fn=<AddBackward0>) tensor(163.6767, grad_fn=<SumBackward0>)\n",
      "tensor(516993.8750, grad_fn=<AddBackward0>) tensor(162.8636, grad_fn=<SumBackward0>)\n",
      "tensor(534433.4375, grad_fn=<AddBackward0>) tensor(168.3298, grad_fn=<SumBackward0>)\n",
      "tensor(559175.3125, grad_fn=<AddBackward0>) tensor(176.0994, grad_fn=<SumBackward0>)\n",
      "tensor(525368., grad_fn=<AddBackward0>) tensor(165.5295, grad_fn=<SumBackward0>)\n",
      "tensor(537528.6875, grad_fn=<AddBackward0>) tensor(169.4542, grad_fn=<SumBackward0>)\n",
      "tensor(508202.8750, grad_fn=<AddBackward0>) tensor(160.2493, grad_fn=<SumBackward0>)\n",
      "tensor(520738.8438, grad_fn=<AddBackward0>) tensor(164.1561, grad_fn=<SumBackward0>)\n",
      "tensor(481738.9688, grad_fn=<AddBackward0>) tensor(151.8474, grad_fn=<SumBackward0>)\n",
      "tensor(520526.3750, grad_fn=<AddBackward0>) tensor(164.1484, grad_fn=<SumBackward0>)\n",
      "tensor(543933.5625, grad_fn=<AddBackward0>) tensor(171.5689, grad_fn=<SumBackward0>)\n",
      "tensor(507077.7188, grad_fn=<AddBackward0>) tensor(160.0269, grad_fn=<SumBackward0>)\n",
      "tensor(516058.4375, grad_fn=<AddBackward0>) tensor(162.7942, grad_fn=<SumBackward0>)\n",
      "tensor(530436.7500, grad_fn=<AddBackward0>) tensor(167.3236, grad_fn=<SumBackward0>)\n",
      "tensor(520356.4375, grad_fn=<AddBackward0>) tensor(164.2257, grad_fn=<SumBackward0>)\n",
      "tensor(517764.9688, grad_fn=<AddBackward0>) tensor(163.3994, grad_fn=<SumBackward0>)\n",
      "tensor(505149.7188, grad_fn=<AddBackward0>) tensor(159.4292, grad_fn=<SumBackward0>)\n",
      "tensor(503112.7500, grad_fn=<AddBackward0>) tensor(158.7749, grad_fn=<SumBackward0>)\n",
      "tensor(552742.7500, grad_fn=<AddBackward0>) tensor(174.3834, grad_fn=<SumBackward0>)\n",
      "tensor(512284.6562, grad_fn=<AddBackward0>) tensor(161.6861, grad_fn=<SumBackward0>)\n",
      "tensor(547183.8125, grad_fn=<AddBackward0>) tensor(172.7295, grad_fn=<SumBackward0>)\n",
      "tensor(532764.7500, grad_fn=<AddBackward0>) tensor(168.1909, grad_fn=<SumBackward0>)\n",
      "tensor(514861.8125, grad_fn=<AddBackward0>) tensor(162.4224, grad_fn=<SumBackward0>)\n",
      "tensor(506752.6562, grad_fn=<AddBackward0>) tensor(160.0079, grad_fn=<SumBackward0>)\n",
      "tensor(512954.6875, grad_fn=<AddBackward0>) tensor(161.8632, grad_fn=<SumBackward0>)\n",
      "tensor(536784.1250, grad_fn=<AddBackward0>) tensor(169.3969, grad_fn=<SumBackward0>)\n",
      "tensor(513754.4062, grad_fn=<AddBackward0>) tensor(162.0810, grad_fn=<SumBackward0>)\n",
      "tensor(527692.8750, grad_fn=<AddBackward0>) tensor(166.4131, grad_fn=<SumBackward0>)\n",
      "tensor(555642.4375, grad_fn=<AddBackward0>) tensor(175.4213, grad_fn=<SumBackward0>)\n",
      "tensor(547016.5625, grad_fn=<AddBackward0>) tensor(172.6627, grad_fn=<SumBackward0>)\n",
      "tensor(506064.9688, grad_fn=<AddBackward0>) tensor(159.7444, grad_fn=<SumBackward0>)\n",
      "tensor(498709.0625, grad_fn=<AddBackward0>) tensor(157.4865, grad_fn=<SumBackward0>)\n",
      "tensor(533466.0625, grad_fn=<AddBackward0>) tensor(168.2360, grad_fn=<SumBackward0>)\n",
      "tensor(499926., grad_fn=<AddBackward0>) tensor(157.6546, grad_fn=<SumBackward0>)\n",
      "tensor(502377.3750, grad_fn=<AddBackward0>) tensor(158.5091, grad_fn=<SumBackward0>)\n",
      "tensor(508408.6562, grad_fn=<AddBackward0>) tensor(160.3689, grad_fn=<SumBackward0>)\n",
      "tensor(541967.6875, grad_fn=<AddBackward0>) tensor(170.9491, grad_fn=<SumBackward0>)\n",
      "tensor(527074.1250, grad_fn=<AddBackward0>) tensor(166.2907, grad_fn=<SumBackward0>)\n",
      "tensor(514255.9062, grad_fn=<AddBackward0>) tensor(162.2140, grad_fn=<SumBackward0>)\n",
      "tensor(512068.3438, grad_fn=<AddBackward0>) tensor(161.4770, grad_fn=<SumBackward0>)\n",
      "tensor(513074.5312, grad_fn=<AddBackward0>) tensor(161.8219, grad_fn=<SumBackward0>)\n",
      "tensor(515290.0312, grad_fn=<AddBackward0>) tensor(162.6377, grad_fn=<SumBackward0>)\n",
      "tensor(501384.5938, grad_fn=<AddBackward0>) tensor(157.9929, grad_fn=<SumBackward0>)\n",
      "tensor(497144.9375, grad_fn=<AddBackward0>) tensor(156.6462, grad_fn=<SumBackward0>)\n",
      "tensor(518838.3125, grad_fn=<AddBackward0>) tensor(163.5450, grad_fn=<SumBackward0>)\n",
      "tensor(520004.3125, grad_fn=<AddBackward0>) tensor(163.7971, grad_fn=<SumBackward0>)\n",
      "tensor(507498.4062, grad_fn=<AddBackward0>) tensor(159.8608, grad_fn=<SumBackward0>)\n",
      "tensor(500516.5625, grad_fn=<AddBackward0>) tensor(157.8525, grad_fn=<SumBackward0>)\n",
      "tensor(509744.6875, grad_fn=<AddBackward0>) tensor(160.7195, grad_fn=<SumBackward0>)\n",
      "tensor(527461.5000, grad_fn=<AddBackward0>) tensor(166.2997, grad_fn=<SumBackward0>)\n",
      "tensor(506999.1250, grad_fn=<AddBackward0>) tensor(159.6546, grad_fn=<SumBackward0>)\n",
      "tensor(501860.5938, grad_fn=<AddBackward0>) tensor(158.1749, grad_fn=<SumBackward0>)\n",
      "tensor(507054.3750, grad_fn=<AddBackward0>) tensor(159.8194, grad_fn=<SumBackward0>)\n",
      "tensor(527075.8750, grad_fn=<AddBackward0>) tensor(165.9213, grad_fn=<SumBackward0>)\n",
      "tensor(517535.0938, grad_fn=<AddBackward0>) tensor(163.0936, grad_fn=<SumBackward0>)\n",
      "tensor(527779.4375, grad_fn=<AddBackward0>) tensor(166.3574, grad_fn=<SumBackward0>)\n",
      "tensor(524347.8125, grad_fn=<AddBackward0>) tensor(165.1437, grad_fn=<SumBackward0>)\n",
      "tensor(499778.3750, grad_fn=<AddBackward0>) tensor(157.2708, grad_fn=<SumBackward0>)\n",
      "tensor(515570.4375, grad_fn=<AddBackward0>) tensor(162.3483, grad_fn=<SumBackward0>)\n",
      "tensor(491213.1875, grad_fn=<AddBackward0>) tensor(154.7896, grad_fn=<SumBackward0>)\n",
      "tensor(530678.9375, grad_fn=<AddBackward0>) tensor(167.2187, grad_fn=<SumBackward0>)\n",
      "tensor(506966.0938, grad_fn=<AddBackward0>) tensor(159.6608, grad_fn=<SumBackward0>)\n",
      "tensor(517277.7812, grad_fn=<AddBackward0>) tensor(162.9321, grad_fn=<SumBackward0>)\n",
      "tensor(520451.6562, grad_fn=<AddBackward0>) tensor(164.0438, grad_fn=<SumBackward0>)\n",
      "tensor(518407.3750, grad_fn=<AddBackward0>) tensor(163.5256, grad_fn=<SumBackward0>)\n",
      "tensor(525936.6875, grad_fn=<AddBackward0>) tensor(165.8580, grad_fn=<SumBackward0>)\n",
      "tensor(505301.8125, grad_fn=<AddBackward0>) tensor(159.2862, grad_fn=<SumBackward0>)\n",
      "tensor(492413.1562, grad_fn=<AddBackward0>) tensor(155.3786, grad_fn=<SumBackward0>)\n",
      "tensor(513219.8125, grad_fn=<AddBackward0>) tensor(162.0239, grad_fn=<SumBackward0>)\n",
      "tensor(497179.6250, grad_fn=<AddBackward0>) tensor(156.7627, grad_fn=<SumBackward0>)\n",
      "tensor(525029.6250, grad_fn=<AddBackward0>) tensor(165.6430, grad_fn=<SumBackward0>)\n",
      "tensor(519688.1250, grad_fn=<AddBackward0>) tensor(163.9447, grad_fn=<SumBackward0>)\n",
      "tensor(506481.6250, grad_fn=<AddBackward0>) tensor(159.8497, grad_fn=<SumBackward0>)\n",
      "tensor(510412.7500, grad_fn=<AddBackward0>) tensor(161.0730, grad_fn=<SumBackward0>)\n",
      "tensor(499410.0312, grad_fn=<AddBackward0>) tensor(157.5741, grad_fn=<SumBackward0>)\n",
      "tensor(504419.2500, grad_fn=<AddBackward0>) tensor(159.1332, grad_fn=<SumBackward0>)\n",
      "tensor(513573.6250, grad_fn=<AddBackward0>) tensor(161.9399, grad_fn=<SumBackward0>)\n",
      "tensor(530360.6875, grad_fn=<AddBackward0>) tensor(167.3784, grad_fn=<SumBackward0>)\n",
      "tensor(519678.8438, grad_fn=<AddBackward0>) tensor(163.9755, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(497808.8125, grad_fn=<AddBackward0>) tensor(157.0738, grad_fn=<SumBackward0>)\n",
      "tensor(526146.0625, grad_fn=<AddBackward0>) tensor(166.0571, grad_fn=<SumBackward0>)\n",
      "tensor(506659.4062, grad_fn=<AddBackward0>) tensor(159.9553, grad_fn=<SumBackward0>)\n",
      "tensor(520935.1250, grad_fn=<AddBackward0>) tensor(164.5005, grad_fn=<SumBackward0>)\n",
      "tensor(516638.9375, grad_fn=<AddBackward0>) tensor(163.2320, grad_fn=<SumBackward0>)\n",
      "tensor(513636., grad_fn=<AddBackward0>) tensor(162.0695, grad_fn=<SumBackward0>)\n",
      "tensor(512281.3125, grad_fn=<AddBackward0>) tensor(161.5989, grad_fn=<SumBackward0>)\n",
      "tensor(514154.4062, grad_fn=<AddBackward0>) tensor(162.3782, grad_fn=<SumBackward0>)\n",
      "tensor(519946., grad_fn=<AddBackward0>) tensor(164.1726, grad_fn=<SumBackward0>)\n",
      "tensor(528104.6250, grad_fn=<AddBackward0>) tensor(166.7377, grad_fn=<SumBackward0>)\n",
      "tensor(512023.2812, grad_fn=<AddBackward0>) tensor(161.6822, grad_fn=<SumBackward0>)\n",
      "tensor(488390.8125, grad_fn=<AddBackward0>) tensor(154.1080, grad_fn=<SumBackward0>)\n",
      "tensor(490219.1875, grad_fn=<AddBackward0>) tensor(154.7504, grad_fn=<SumBackward0>)\n",
      "tensor(514728.9375, grad_fn=<AddBackward0>) tensor(162.4882, grad_fn=<SumBackward0>)\n",
      "tensor(502476.0625, grad_fn=<AddBackward0>) tensor(158.6187, grad_fn=<SumBackward0>)\n",
      "tensor(502473.8438, grad_fn=<AddBackward0>) tensor(158.6282, grad_fn=<SumBackward0>)\n",
      "tensor(519173.5312, grad_fn=<AddBackward0>) tensor(163.8384, grad_fn=<SumBackward0>)\n",
      "tensor(509610.4375, grad_fn=<AddBackward0>) tensor(160.8277, grad_fn=<SumBackward0>)\n",
      "tensor(521507.6562, grad_fn=<AddBackward0>) tensor(164.6942, grad_fn=<SumBackward0>)\n",
      "tensor(518363.4062, grad_fn=<AddBackward0>) tensor(163.6826, grad_fn=<SumBackward0>)\n",
      "tensor(499072.5000, grad_fn=<AddBackward0>) tensor(157.6195, grad_fn=<SumBackward0>)\n",
      "tensor(510084.5625, grad_fn=<AddBackward0>) tensor(161.0354, grad_fn=<SumBackward0>)\n",
      "tensor(520229.2500, grad_fn=<AddBackward0>) tensor(164.1899, grad_fn=<SumBackward0>)\n",
      "tensor(506916.4062, grad_fn=<AddBackward0>) tensor(160.0433, grad_fn=<SumBackward0>)\n",
      "tensor(503821.9375, grad_fn=<AddBackward0>) tensor(158.9486, grad_fn=<SumBackward0>)\n",
      "tensor(502830.0938, grad_fn=<AddBackward0>) tensor(158.6720, grad_fn=<SumBackward0>)\n",
      "tensor(492741.4062, grad_fn=<AddBackward0>) tensor(155.5717, grad_fn=<SumBackward0>)\n",
      "tensor(505266.1562, grad_fn=<AddBackward0>) tensor(159.4110, grad_fn=<SumBackward0>)\n",
      "tensor(525675.1250, grad_fn=<AddBackward0>) tensor(165.9318, grad_fn=<SumBackward0>)\n",
      "tensor(500571.7812, grad_fn=<AddBackward0>) tensor(158.0090, grad_fn=<SumBackward0>)\n",
      "tensor(505206.9375, grad_fn=<AddBackward0>) tensor(159.4497, grad_fn=<SumBackward0>)\n",
      "tensor(507990.7812, grad_fn=<AddBackward0>) tensor(160.4821, grad_fn=<SumBackward0>)\n",
      "tensor(502319.5625, grad_fn=<AddBackward0>) tensor(158.5643, grad_fn=<SumBackward0>)\n",
      "tensor(513254.3750, grad_fn=<AddBackward0>) tensor(161.9397, grad_fn=<SumBackward0>)\n",
      "tensor(517456.5000, grad_fn=<AddBackward0>) tensor(163.3492, grad_fn=<SumBackward0>)\n",
      "tensor(510226.9688, grad_fn=<AddBackward0>) tensor(161.1363, grad_fn=<SumBackward0>)\n",
      "tensor(491376.7812, grad_fn=<AddBackward0>) tensor(155.0428, grad_fn=<SumBackward0>)\n",
      "tensor(482687.9688, grad_fn=<AddBackward0>) tensor(152.3352, grad_fn=<SumBackward0>)\n",
      "tensor(531771.5000, grad_fn=<AddBackward0>) tensor(167.7340, grad_fn=<SumBackward0>)\n",
      "tensor(505854.9688, grad_fn=<AddBackward0>) tensor(159.6437, grad_fn=<SumBackward0>)\n",
      "tensor(526086., grad_fn=<AddBackward0>) tensor(165.9272, grad_fn=<SumBackward0>)\n",
      "tensor(482027., grad_fn=<AddBackward0>) tensor(152.1858, grad_fn=<SumBackward0>)\n",
      "tensor(526642.4375, grad_fn=<AddBackward0>) tensor(166.3916, grad_fn=<SumBackward0>)\n",
      "tensor(532606.0625, grad_fn=<AddBackward0>) tensor(168.0457, grad_fn=<SumBackward0>)\n",
      "tensor(507738.6562, grad_fn=<AddBackward0>) tensor(160.2123, grad_fn=<SumBackward0>)\n",
      "tensor(510921., grad_fn=<AddBackward0>) tensor(161.2320, grad_fn=<SumBackward0>)\n",
      "tensor(510920.4688, grad_fn=<AddBackward0>) tensor(161.1868, grad_fn=<SumBackward0>)\n",
      "tensor(494396.3438, grad_fn=<AddBackward0>) tensor(156.0613, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-590-d11413934308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0_distribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-589-04bc25a837e6>\u001b[0m in \u001b[0;36msimulation\u001b[0;34m(net, g)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleapfrog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0_distribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-585-d48de8af6a6f>\u001b[0m in \u001b[0;36mleapfrog\u001b[0;34m(xs, vs, closure, dt)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0menergy_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     a = -torch.autograd.grad(\n",
      "\u001b[0;32m<ipython-input-589-04bc25a837e6>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleapfrog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0_distribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-588-b32dbe83ffe8>\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(x, idx, g)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'k_ref'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mrealize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheterograph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'u_ref'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pinot/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pinot/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pinot/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/espaloma/espaloma/mm/geometry.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgeometry_in_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/espaloma/espaloma/mm/geometry.py\u001b[0m in \u001b[0;36mgeometry_in_graph\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n4\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_torsion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"n4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;31m# copy coordinates to nonbonded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pinot/lib/python3.7/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mapply_nodes\u001b[0;34m(self, func, v, ntype, inplace)\u001b[0m\n\u001b[1;32m   3963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3964\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3965\u001b[0;31m         \u001b[0mndata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_node_udf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_nid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3966\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_n_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pinot/lib/python3.7/site-packages/dgl/core.py\u001b[0m in \u001b[0;36minvoke_node_udf\u001b[0;34m(graph, nid, ntype, func, ndata, orig_nid)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mndata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mntid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mnbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNodeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnid\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0morig_nid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0morig_nid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minvoke_edge_udf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_eid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/espaloma/espaloma/mm/geometry.py\u001b[0m in \u001b[0;36mapply_torsion\u001b[0;34m(nodes)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mx1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"xyz1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mx2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"xyz2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mx3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"xyz3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         )\n\u001b[1;32m    100\u001b[0m     }\n",
      "\u001b[0;32m~/Documents/GitHub/espaloma/espaloma/mm/geometry.py\u001b[0m in \u001b[0;36mdihedral\u001b[0;34m(x0, x1, x2, x3, jitter)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_dihedral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/espaloma/espaloma/mm/geometry.py\u001b[0m in \u001b[0;36m_dihedral\u001b[0;34m(r0, r1)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_dihedral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;34m\"\"\" Dihedral between normal vectors. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_angle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/espaloma/espaloma/mm/geometry.py\u001b[0m in \u001b[0;36m_angle\u001b[0;34m(r0, r1)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     angle = torch.atan2(\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/envs/pinot/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), 1e-5)\n",
    "normal_distribution = torch.distributions.normal.Normal(0, 1.0)\n",
    "\n",
    "for _ in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    xs, vs, x0_distribution, det_j = simulation(net)\n",
    "    \n",
    "    energy = closure(xs[-1], idx=-1).sum()\n",
    "    \n",
    "    log_p = -energy/kT + normal_distribution.log_prob(vs[-1]).sum()\n",
    "    \n",
    "    log_q = -det_j.sum() * 3 + normal_distribution.log_prob(vs[0]).sum() + x0_distribution.log_prob(xs[0]).sum()\n",
    "        \n",
    "    loss = -log_p + log_q\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    print(loss, energy)\n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, vs, particle_distribution, _ = simulation(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15cf04a214c4728b8e64a0edc9a0f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nglview as nv\n",
    "from rdkit.Geometry import Point3D\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "conf_idx = 1\n",
    "\n",
    "mol = g.mol.to_rdkit()\n",
    "AllChem.EmbedMolecule(mol)\n",
    "conf = mol.GetConformer()\n",
    "\n",
    "xs, vs, particle_distribution, _ = simulation(net)\n",
    "x = xs[-1]\n",
    "\n",
    "\n",
    "for idx_atom in range(mol.GetNumAtoms()):\n",
    "    conf.SetAtomPosition(\n",
    "        idx_atom,\n",
    "        Point3D(\n",
    "            float(x[idx_atom, conf_idx, 0]),\n",
    "            float(x[idx_atom, conf_idx, 1]),\n",
    "            float(x[idx_atom, conf_idx, 2]),\n",
    "        ))\n",
    "    \n",
    "nv.show_rdkit(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'g': 1, 'n1': 8, 'n2': 14, 'n3': 24, 'n4': 18, 'nonbonded': 0, 'onefour': 18},\n",
       "      num_edges={('g', 'g_has_n1', 'n1'): 8, ('g', 'g_has_n2', 'n2'): 14, ('g', 'g_has_n3', 'n3'): 24, ('g', 'g_has_n4', 'n4'): 18, ('g', 'g_has_nonbonded', 'nonbonded'): 0, ('g', 'g_has_onefour', 'onefour'): 18, ('n1', 'n1_as_0_in_n2', 'n2'): 14, ('n1', 'n1_as_0_in_n3', 'n3'): 24, ('n1', 'n1_as_0_in_n4', 'n4'): 18, ('n1', 'n1_as_0_in_nonbonded', 'nonbonded'): 0, ('n1', 'n1_as_0_in_onefour', 'onefour'): 18, ('n1', 'n1_as_1_in_n2', 'n2'): 14, ('n1', 'n1_as_1_in_n3', 'n3'): 24, ('n1', 'n1_as_1_in_n4', 'n4'): 18, ('n1', 'n1_as_1_in_nonbonded', 'nonbonded'): 0, ('n1', 'n1_as_1_in_onefour', 'onefour'): 18, ('n1', 'n1_as_2_in_n3', 'n3'): 24, ('n1', 'n1_as_2_in_n4', 'n4'): 18, ('n1', 'n1_as_3_in_n4', 'n4'): 18, ('n1', 'n1_in_g', 'g'): 8, ('n1', 'n1_neighbors_n1', 'n1'): 14, ('n2', 'n2_as_0_in_n3', 'n3'): 24, ('n2', 'n2_as_0_in_n4', 'n4'): 18, ('n2', 'n2_as_1_in_n3', 'n3'): 24, ('n2', 'n2_as_1_in_n4', 'n4'): 18, ('n2', 'n2_as_2_in_n4', 'n4'): 18, ('n2', 'n2_has_0_n1', 'n1'): 14, ('n2', 'n2_has_1_n1', 'n1'): 14, ('n2', 'n2_in_g', 'g'): 14, ('n3', 'n3_as_0_in_n4', 'n4'): 18, ('n3', 'n3_as_1_in_n4', 'n4'): 18, ('n3', 'n3_has_0_n1', 'n1'): 24, ('n3', 'n3_has_0_n2', 'n2'): 24, ('n3', 'n3_has_1_n1', 'n1'): 24, ('n3', 'n3_has_1_n2', 'n2'): 24, ('n3', 'n3_has_2_n1', 'n1'): 24, ('n3', 'n3_in_g', 'g'): 24, ('n4', 'n4_has_0_n1', 'n1'): 18, ('n4', 'n4_has_0_n2', 'n2'): 18, ('n4', 'n4_has_0_n3', 'n3'): 18, ('n4', 'n4_has_1_n1', 'n1'): 18, ('n4', 'n4_has_1_n2', 'n2'): 18, ('n4', 'n4_has_1_n3', 'n3'): 18, ('n4', 'n4_has_2_n1', 'n1'): 18, ('n4', 'n4_has_2_n2', 'n2'): 18, ('n4', 'n4_has_3_n1', 'n1'): 18, ('n4', 'n4_in_g', 'g'): 18, ('nonbonded', 'nonbonded_has_0_n1', 'n1'): 0, ('nonbonded', 'nonbonded_has_1_n1', 'n1'): 0, ('nonbonded', 'nonbonded_in_g', 'g'): 0, ('onefour', 'onefour_has_0_n1', 'n1'): 18, ('onefour', 'onefour_has_1_n1', 'n1'): 18, ('onefour', 'onefour_in_g', 'g'): 18},\n",
       "      metagraph=[('g', 'n1', 'g_has_n1'), ('g', 'n2', 'g_has_n2'), ('g', 'n3', 'g_has_n3'), ('g', 'n4', 'g_has_n4'), ('g', 'nonbonded', 'g_has_nonbonded'), ('g', 'onefour', 'g_has_onefour'), ('n1', 'n2', 'n1_as_0_in_n2'), ('n1', 'n2', 'n1_as_1_in_n2'), ('n1', 'n3', 'n1_as_0_in_n3'), ('n1', 'n3', 'n1_as_1_in_n3'), ('n1', 'n3', 'n1_as_2_in_n3'), ('n1', 'n4', 'n1_as_0_in_n4'), ('n1', 'n4', 'n1_as_1_in_n4'), ('n1', 'n4', 'n1_as_2_in_n4'), ('n1', 'n4', 'n1_as_3_in_n4'), ('n1', 'nonbonded', 'n1_as_0_in_nonbonded'), ('n1', 'nonbonded', 'n1_as_1_in_nonbonded'), ('n1', 'onefour', 'n1_as_0_in_onefour'), ('n1', 'onefour', 'n1_as_1_in_onefour'), ('n1', 'g', 'n1_in_g'), ('n1', 'n1', 'n1_neighbors_n1'), ('n2', 'n3', 'n2_as_0_in_n3'), ('n2', 'n3', 'n2_as_1_in_n3'), ('n2', 'n4', 'n2_as_0_in_n4'), ('n2', 'n4', 'n2_as_1_in_n4'), ('n2', 'n4', 'n2_as_2_in_n4'), ('n2', 'n1', 'n2_has_0_n1'), ('n2', 'n1', 'n2_has_1_n1'), ('n2', 'g', 'n2_in_g'), ('n3', 'n4', 'n3_as_0_in_n4'), ('n3', 'n4', 'n3_as_1_in_n4'), ('n3', 'n1', 'n3_has_0_n1'), ('n3', 'n1', 'n3_has_1_n1'), ('n3', 'n1', 'n3_has_2_n1'), ('n3', 'n2', 'n3_has_0_n2'), ('n3', 'n2', 'n3_has_1_n2'), ('n3', 'g', 'n3_in_g'), ('n4', 'n1', 'n4_has_0_n1'), ('n4', 'n1', 'n4_has_1_n1'), ('n4', 'n1', 'n4_has_2_n1'), ('n4', 'n1', 'n4_has_3_n1'), ('n4', 'n2', 'n4_has_0_n2'), ('n4', 'n2', 'n4_has_1_n2'), ('n4', 'n2', 'n4_has_2_n2'), ('n4', 'n3', 'n4_has_0_n3'), ('n4', 'n3', 'n4_has_1_n3'), ('n4', 'g', 'n4_in_g'), ('nonbonded', 'n1', 'nonbonded_has_0_n1'), ('nonbonded', 'n1', 'nonbonded_has_1_n1'), ('nonbonded', 'g', 'nonbonded_in_g'), ('onefour', 'n1', 'onefour_has_0_n1'), ('onefour', 'n1', 'onefour_has_1_n1'), ('onefour', 'g', 'onefour_in_g')])"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = esp.Graph('CC')\n",
    "g = esp.graphs.LegacyForceField('smirnoff99Frosst').parametrize(g)\n",
    "g.nodes['n1'].data['xyz'] = xs[-1]\n",
    "realize(g.heterograph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.hist(\n",
    "    g.nodes['n3'].data['x'].flatten().detach().numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openforcefield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangy1/anaconda3/envs/pinot/lib/python3.7/site-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<espaloma.graphs.graph.Graph at 0x13c2786d0>"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from espaloma.data.md import MoleculeVacuumSimulation\n",
    "simulation = MoleculeVacuumSimulation(\n",
    "    n_samples=128, n_steps_per_sample=10,\n",
    ")\n",
    "g = esp.Graph('C')\n",
    "g = esp.graphs.LegacyForceField('smirnoff99Frosst').parametrize(g)\n",
    "simulation.run(g, in_place=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 18.,  48., 116., 216., 250., 224.,  98.,  46.,   4.,   4.]),\n",
       " array([1.899204 , 1.9360824, 1.9729607, 2.009839 , 2.0467174, 2.0835958,\n",
       "        2.120474 , 2.1573524, 2.1942308, 2.2311091, 2.2679875],\n",
       "       dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "esp.mm.geometry.geometry_in_graph(g.heterograph)\n",
    "plt.hist(\n",
    "    g.nodes['n2'].data['x'].flatten().cpu().detach().numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  6.,  42.,  82., 216., 328., 412., 276., 120.,  38.,  16.]),\n",
       " array([1.6291838, 1.6830696, 1.7369553, 1.7908411, 1.8447268, 1.8986126,\n",
       "        1.9524984, 2.0063841, 2.0602698, 2.1141558, 2.1680415],\n",
       "       dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAR9klEQVR4nO3df4xdZ53f8fdnvWnYFlgcZZIa2+1EyLuLg4qpRi4VlUo3q8ZL2jpUysqRyroolfnDtEGirWz+gf3Dkqvyo622oTJLFG+XkloCFJdsf2S9sJRqGzNhTYhtIizsJoMtexZ2C1Elt3a+/WNOlos94zkz99658ZP3S7q65zznOfd8HyX6zPFzz7knVYUkqS0/M+kCJEmjZ7hLUoMMd0lqkOEuSQ0y3CWpQT876QIAbr/99pqenp50GZJ0U3nmmWf+uKqmFtv2qgj36elpZmdnJ12GJN1UkvyvpbY5LSNJDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ16VdyhKr2aTe97ciLHPXfwvokcV23wzF2SGmS4S1KDeod7knVJ/ijJl7v125I8leS73fv6gb77k5xJ8nySe8dRuCRpaSs5c38YOD2wvg84VlVbgGPdOkm2AruAu4EdwCNJ1o2mXElSH73CPckm4D7gtwaadwKHu+XDwP0D7Y9X1eWqOgucAbaPplxJUh99z9z/FfDPgZcH2u6sqgsA3fsdXftG4MWBfnNd209JsifJbJLZ+fn5FRcuSVrasuGe5O8Al6rqmZ6fmUXa6rqGqkNVNVNVM1NTiz5IRJK0Sn2uc38X8PeSvAd4HfDGJL8DXEyyoaouJNkAXOr6zwGbB/bfBJwfZdGSpBtb9sy9qvZX1aaqmmbhi9Lfr6p/ABwFdnfddgNPdMtHgV1Jbk1yF7AFOD7yyiVJSxrmDtWDwJEkDwEvAA8AVNXJJEeAU8AVYG9VXR26UklSbysK96r6KvDVbvkHwD1L9DsAHBiyNknSKnmHqiQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQX0ekP26JMeTfCvJySS/0bV/LMn3k5zoXu8Z2Gd/kjNJnk9y7zgHIEm6Xp8nMV0GfrmqXkpyC/D1JP+52/apqvr4YOckW1l41urdwJuB30vyCz5qT5LWTp8HZFdVvdSt3tK96ga77AQer6rLVXUWOANsH7pSSVJvvebck6xLcgK4BDxVVU93mz6Y5NkkjyZZ37VtBF4c2H2ua7v2M/ckmU0yOz8/P8QQJEnX6hXuVXW1qrYBm4DtSd4GfBp4C7ANuAB8ouuexT5ikc88VFUzVTUzNTW1quIlSYtb0dUyVfWnwFeBHVV1sQv9l4HP8JOplzlg88Bum4DzI6hVktRTn6tlppK8qVv+OeBXgO8k2TDQ7b3Ac93yUWBXkluT3AVsAY6PtmxJ0o30uVpmA3A4yToW/hgcqaovJ/n3SbaxMOVyDvgAQFWdTHIEOAVcAfZ6pYwkra1lw72qngXesUj7+26wzwHgwHClSZJWyztUJalBhrskNchwl6QGGe6S1CDDXZIa1OdSSGnipvc9OekSpJuKZ+6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGtTnMXuvS3I8ybeSnEzyG137bUmeSvLd7n39wD77k5xJ8nySe8c5AEnS9fqcuV8Gfrmq3g5sA3YkeSewDzhWVVuAY906SbYCu4C7gR3AI90j+iRJa2TZcK8FL3Wrt3SvAnYCh7v2w8D93fJO4PGqulxVZ4EzwPaRVi1JuqFec+5J1iU5AVwCnqqqp4E7q+oCQPd+R9d9I/DiwO5zXdu1n7knyWyS2fn5+WHGIEm6Rq9wr6qrVbUN2ARsT/K2G3TPYh+xyGceqqqZqpqZmprqV60kqZcVXS1TVX8KfJWFufSLSTYAdO+Xum5zwOaB3TYB54euVJLUW5+rZaaSvKlb/jngV4DvAEeB3V233cAT3fJRYFeSW5PcBWwBjo+6cEnS0vo8iWkDcLi74uVngCNV9eUkfwgcSfIQ8ALwAEBVnUxyBDgFXAH2VtXV8ZQvSVrMsuFeVc8C71ik/QfAPUvscwA4MHR1kqRV8Q5VSWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1KA+17lLmoDpfU9O7NjnDt43sWNrNDxzl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBvV5zN7mJF9JcjrJySQPd+0fS/L9JCe613sG9tmf5EyS55PcO84BSJKu1+fnB64AH66qbyZ5A/BMkqe6bZ+qqo8Pdk6yFdgF3A28Gfi9JL/go/Ykae0se+ZeVReq6pvd8o+B08DGG+yyE3i8qi5X1VngDLB9FMVKkvpZ0Zx7kmkWnqf6dNf0wSTPJnk0yfqubSPw4sBucyzyxyDJniSzSWbn5+dXXLgkaWm9wz3J64EvAB+qqh8BnwbeAmwDLgCfeKXrIrvXdQ1Vh6pqpqpmpqamVly4JGlpvcI9yS0sBPvnquqLAFV1saquVtXLwGf4ydTLHLB5YPdNwPnRlSxJWk6fq2UCfBY4XVWfHGjfMNDtvcBz3fJRYFeSW5PcBWwBjo+uZEnScvpcLfMu4H3At5Oc6No+AjyYZBsLUy7ngA8AVNXJJEeAUyxcabPXK2UkaW0tG+5V9XUWn0f/3RvscwA4MERdkqQheIeqJDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUoD4/HCb9mel9T066BEk9eOYuSQ0y3CWpQYa7JDXIcJekBvV5zN7mJF9JcjrJySQPd+23JXkqyXe79/UD++xPcibJ80nuHecAJEnX63PmfgX4cFW9FXgnsDfJVmAfcKyqtgDHunW6bbuAu4EdwCNJ1o2jeEnS4pYN96q6UFXf7JZ/DJwGNgI7gcNdt8PA/d3yTuDxqrpcVWeBM8D2URcuSVraiubck0wD7wCeBu6sqguw8AcAuKPrthF4cWC3ua7t2s/ak2Q2yez8/PzKK5ckLal3uCd5PfAF4ENV9aMbdV2kra5rqDpUVTNVNTM1NdW3DElSD73CPcktLAT756rqi13zxSQbuu0bgEtd+xyweWD3TcD50ZQrSeqjz9UyAT4LnK6qTw5sOgrs7pZ3A08MtO9KcmuSu4AtwPHRlSxJWk6f35Z5F/A+4NtJTnRtHwEOAkeSPAS8ADwAUFUnkxwBTrFwpc3eqro68solSUtaNtyr6ussPo8OcM8S+xwADgxRlyRpCN6hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqUJ/H7D2a5FKS5wbaPpbk+0lOdK/3DGzbn+RMkueT3DuuwiVJS+tz5v4YsGOR9k9V1bbu9bsASbYCu4C7u30eSbJuVMVKkvpZNtyr6mvAD3t+3k7g8aq6XFVngTPA9iHqkyStwjBz7h9M8mw3bbO+a9sIvDjQZ65ru06SPUlmk8zOz88PUYYk6VqrDfdPA28BtgEXgE907Ys9SLsW+4CqOlRVM1U1MzU1tcoyJEmLWVW4V9XFqrpaVS8Dn+EnUy9zwOaBrpuA88OVKElaqVWFe5INA6vvBV65kuYosCvJrUnuArYAx4crUZK0Uj+7XIcknwfeDdyeZA74KPDuJNtYmHI5B3wAoKpOJjkCnAKuAHur6up4SpckLWXZcK+qBxdp/uwN+h8ADgxTlCRpON6hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDVr2DlVJrz3T+56cyHHPHbxvIsdtkWfuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUHLhnuSR5NcSvLcQNttSZ5K8t3uff3Atv1JziR5Psm94ypckrS0PmfujwE7rmnbBxyrqi3AsW6dJFuBXcDd3T6PJFk3smolSb0sG+5V9TXgh9c07wQOd8uHgfsH2h+vqstVdRY4A2wfUa2SpJ5WO+d+Z1VdAOje7+jaNwIvDvSb69okSWto1F+oZpG2WrRjsifJbJLZ+fn5EZchSa9tqw33i0k2AHTvl7r2OWDzQL9NwPnFPqCqDlXVTFXNTE1NrbIMSdJiVhvuR4Hd3fJu4ImB9l1Jbk1yF7AFOD5ciZKklVr2VyGTfB54N3B7kjngo8BB4EiSh4AXgAcAqupkkiPAKeAKsLeqro6pdknSEpYN96p6cIlN9yzR/wBwYJiiJEnD8Q5VSWqQ4S5JDTLcJalBhrskNchnqN6EJvV8S0k3D8/cJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktSgoX44LMk54MfAVeBKVc0kuQ34j8A0cA74tar6k+HKlCStxCjO3P9WVW2rqplufR9wrKq2AMe6dUnSGhrHtMxO4HC3fBi4fwzHkCTdwLDhXsB/S/JMkj1d251VdQGge79jsR2T7Ekym2R2fn5+yDIkSYOGfVjHu6rqfJI7gKeSfKfvjlV1CDgEMDMzU0PWIUkaMNSZe1Wd794vAV8CtgMXk2wA6N4vDVukJGllVh3uSf5Ckje8sgz8beA54Ciwu+u2G3hi2CIlSSszzLTMncCXkrzyOf+hqv5Lkm8AR5I8BLwAPDB8ma9OPstU0qvVqsO9qr4HvH2R9h8A9wxTlCRpOMN+oSpJIzOpfw2fO3jfRI47Tv78gCQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QG+fMDkl7zJvkjgOP66QPP3CWpQYa7JDXIcJekBhnuktSgsX2hmmQH8K+BdcBvVdXBcR3LJyJJ0k8by5l7knXAvwV+FdgKPJhk6ziOJUm63rimZbYDZ6rqe1X1f4HHgZ1jOpYk6RrjmpbZCLw4sD4H/LXBDkn2AHu61ZeSPD+mWl4Nbgf+eNJFjFHr44P2x+j4JiT/Yqjd//JSG8YV7lmkrX5qpeoQcGhMx39VSTJbVTOTrmNcWh8ftD9Gx9eecU3LzAGbB9Y3AefHdCxJ0jXGFe7fALYkuSvJnwN2AUfHdCxJ0jXGMi1TVVeSfBD4ryxcCvloVZ0cx7FuEq1PP7U+Pmh/jI6vMamq5XtJkm4q3qEqSQ0y3CWpQYb7iCR5NMmlJM8tsf2fJTnRvZ5LcjXJbWtd52r1GN/PJ/lPSb6V5GSS9691jcPqMcb1Sb6U5Nkkx5O8ba1rHEaSzUm+kuR099/o4UX6JMm/SXKmG+dfnUStq9FzfL+U5A+TXE7yTydR51ox3EfnMWDHUhur6l9W1baq2gbsB/6gqn64VsWNwGPcYHzAXuBUVb0deDfwie5KqZvJY9x4jB8BTlTVXwF+nYXfTrqZXAE+XFVvBd4J7F3kZ0F+FdjSvfYAn17bEofSZ3w/BP4J8PG1Lm6tGe4jUlVfY+F/nD4eBD4/xnJGrsf4CnhDkgCv7/peWYvaRqXHGLcCx7q+3wGmk9y5FrWNQlVdqKpvdss/Bk6zcDf5oJ3Ab9eC/wm8KcmGNS51VfqMr6ouVdU3gP83gRLXlOG+xpL8eRbODr8w6VpG7DeBt7Jws9q3gYer6uXJljRy3wL+PkCS7Szc+r1pohWtUpJp4B3A09dsWuynQ679A/Cqd4PxvWYY7mvv7wL/4yabkunjXuAE8GZgG/CbSd442ZJG7iCwPskJ4B8Df8RN9q8TgCSvZ+Hk4kNV9aNrNy+yy011vfQy43vN8AHZa28XN9mUTE/vBw7Wwo0TZ5KcBX4JOD7ZskanC4r3w8IXj8DZ7nXTSHILC8H3uar64iJdbuqfDukxvtcMz9zXUJKfB/4m8MSkaxmDF4B7ALp56F8EvjfRikYsyZsGviT+R8DXbqYzw+4P0meB01X1ySW6HQV+vbtq5p3A/66qC2tW5BB6ju81wztURyTJ51m4SuR24CLwUeAWgKr6d12ffwjsqKpdk6ly9ZYbX5I3s3C1yQYW/ml/sKp+ZyLFrlKPMf514LeBq8Ap4KGq+pPJVLtySf4G8N9Z+E7kle9DPgL8JfizMYaF7092AP8HeH9VzU6g3BXrOb6/CMwCb+z6vARsvZn+SPdluEtSg5yWkaQGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQf8fEi4UUqEoMzIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "esp.mm.geometry.geometry_in_graph(g.heterograph)\n",
    "plt.hist(\n",
    "    g.nodes['n3'].data['x'].flatten().cpu().detach().numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
